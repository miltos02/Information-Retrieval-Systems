{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8093769",
   "metadata": {},
   "source": [
    "# Information Retrieval Systems  \n",
    "\n",
    "### Query extension with synonym terms in an effort to improve retrieval results. \n",
    "by Miltos Tsolkas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c0e1c8",
   "metadata": {},
   "source": [
    "## IR2025 Preprocessing\n",
    "Firstly, we will preprocess the collection of texts IR2025 (which is saved in `corpus.jsonl`) in order to transform them in a form in which it can be used by the ElasticSearch search engine.\n",
    "\n",
    "### Exploration and Loading of Data \n",
    "* We will need the data of `corpus.jsonl` in a format that will be able to be handled simpler, like `pandas dataframe`.\n",
    "* To achieve that we will create a function that scans the entire document and loads in into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3152e7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_ir2025_data(file_path):\n",
    "    documents = []\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            # Parse each JSON line into a dictionary\n",
    "            doc = pd.read_json(line, lines=True)\n",
    "            documents.append(doc)\n",
    "\n",
    "    df = pd.concat(documents, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e460c97",
   "metadata": {},
   "source": [
    "* Now, let's call this function on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf257895",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib, io # so that we don't get a huge cell output\n",
    "\n",
    "file_path = './scidocs/corpus.jsonl'\n",
    "with contextlib.redirect_stdout(io.StringIO()), contextlib.redirect_stderr(io.StringIO()):\n",
    "    data_df = load_ir2025_data(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191d70bd",
   "metadata": {},
   "source": [
    "* Let's see if our data was loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb100924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>632589828c8b9fca2c3a59e97451fde8fa7d188d</td>\n",
       "      <td>A hybrid of genetic algorithm and particle swa...</td>\n",
       "      <td>An evolutionary recurrent network which automa...</td>\n",
       "      <td>{'authors': ['1725986'], 'year': 2004, 'cited_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86e87db2dab958f1bd5877dc7d5b8105d6e31e46</td>\n",
       "      <td>A Hybrid EP and SQP for Dynamic Economic Dispa...</td>\n",
       "      <td>Dynamic economic dispatch (DED) is one of the ...</td>\n",
       "      <td>{'authors': ['30728239', '49115828', '1857220'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2a047d8c4c2a4825e0f0305294e7da14f8de6fd3</td>\n",
       "      <td>Genetic Fuzzy Systems - Evolutionary Tuning an...</td>\n",
       "      <td>It's not surprisingly when entering this site ...</td>\n",
       "      <td>{'authors': ['1685850', '1699069', '34695695',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>506172b0e0dd4269bdcfe96dda9ea9d8602bbfb6</td>\n",
       "      <td>A modified particle swarm optimizer</td>\n",
       "      <td>In this paper, we introduce a new parameter, c...</td>\n",
       "      <td>{'authors': ['8385459', '4298485'], 'year': 19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51317b6082322a96b4570818b7a5ec8b2e330f2f</td>\n",
       "      <td>Identification and control of dynamic systems ...</td>\n",
       "      <td>This paper proposes a recurrent fuzzy neural n...</td>\n",
       "      <td>{'authors': ['34448377', '2062864'], 'year': 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>857a8c6c46b0a85ed6019f5830294872f2f1dcf5</td>\n",
       "      <td>Separate face and body selectivity on the fusi...</td>\n",
       "      <td>Recent reports of a high response to bodies in...</td>\n",
       "      <td>{'authors': ['2981413', '2074160', '1931482'],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12f107016fd3d062dff88a00d6b0f5f81f00522d</td>\n",
       "      <td>Scheduling for Reduced CPU Energy</td>\n",
       "      <td>The energy usage of computer systems is becomi...</td>\n",
       "      <td>{'authors': ['1800362', '9036495', '1686255', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1ae0ac5e13134df7a0d670fc08c2b404f1e3803c</td>\n",
       "      <td>A data mining approach for location prediction...</td>\n",
       "      <td>Mobility prediction is one of the most essenti...</td>\n",
       "      <td>{'authors': ['2108906', '22789555', '1801322',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7d3c9c4064b588d5d8c7c0cb398118aac239c71b</td>\n",
       "      <td>$\\mathsf {pSCAN}$ : Fast and Exact Structural ...</td>\n",
       "      <td>We study the problem of structural graph clust...</td>\n",
       "      <td>{'authors': ['38736958', '35660624', '36838704...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>305c45fb798afdad9e6d34505b4195fa37c2ee4f</td>\n",
       "      <td>Synthesis, properties, and applications of iro...</td>\n",
       "      <td>Iron, the most ubiquitous of the transition me...</td>\n",
       "      <td>{'authors': ['5701357'], 'year': 2005, 'cited_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        _id  \\\n",
       "0  632589828c8b9fca2c3a59e97451fde8fa7d188d   \n",
       "1  86e87db2dab958f1bd5877dc7d5b8105d6e31e46   \n",
       "2  2a047d8c4c2a4825e0f0305294e7da14f8de6fd3   \n",
       "3  506172b0e0dd4269bdcfe96dda9ea9d8602bbfb6   \n",
       "4  51317b6082322a96b4570818b7a5ec8b2e330f2f   \n",
       "5  857a8c6c46b0a85ed6019f5830294872f2f1dcf5   \n",
       "6  12f107016fd3d062dff88a00d6b0f5f81f00522d   \n",
       "7  1ae0ac5e13134df7a0d670fc08c2b404f1e3803c   \n",
       "8  7d3c9c4064b588d5d8c7c0cb398118aac239c71b   \n",
       "9  305c45fb798afdad9e6d34505b4195fa37c2ee4f   \n",
       "\n",
       "                                               title  \\\n",
       "0  A hybrid of genetic algorithm and particle swa...   \n",
       "1  A Hybrid EP and SQP for Dynamic Economic Dispa...   \n",
       "2  Genetic Fuzzy Systems - Evolutionary Tuning an...   \n",
       "3                A modified particle swarm optimizer   \n",
       "4  Identification and control of dynamic systems ...   \n",
       "5  Separate face and body selectivity on the fusi...   \n",
       "6                  Scheduling for Reduced CPU Energy   \n",
       "7  A data mining approach for location prediction...   \n",
       "8  $\\mathsf {pSCAN}$ : Fast and Exact Structural ...   \n",
       "9  Synthesis, properties, and applications of iro...   \n",
       "\n",
       "                                                text  \\\n",
       "0  An evolutionary recurrent network which automa...   \n",
       "1  Dynamic economic dispatch (DED) is one of the ...   \n",
       "2  It's not surprisingly when entering this site ...   \n",
       "3  In this paper, we introduce a new parameter, c...   \n",
       "4  This paper proposes a recurrent fuzzy neural n...   \n",
       "5  Recent reports of a high response to bodies in...   \n",
       "6  The energy usage of computer systems is becomi...   \n",
       "7  Mobility prediction is one of the most essenti...   \n",
       "8  We study the problem of structural graph clust...   \n",
       "9  Iron, the most ubiquitous of the transition me...   \n",
       "\n",
       "                                            metadata  \n",
       "0  {'authors': ['1725986'], 'year': 2004, 'cited_...  \n",
       "1  {'authors': ['30728239', '49115828', '1857220'...  \n",
       "2  {'authors': ['1685850', '1699069', '34695695',...  \n",
       "3  {'authors': ['8385459', '4298485'], 'year': 19...  \n",
       "4  {'authors': ['34448377', '2062864'], 'year': 2...  \n",
       "5  {'authors': ['2981413', '2074160', '1931482'],...  \n",
       "6  {'authors': ['1800362', '9036495', '1686255', ...  \n",
       "7  {'authors': ['2108906', '22789555', '1801322',...  \n",
       "8  {'authors': ['38736958', '35660624', '36838704...  \n",
       "9  {'authors': ['5701357'], 'year': 2005, 'cited_...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0a31ca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['_id', 'title', 'text', 'metadata'], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e8770a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_id         False\n",
      "title       False\n",
      "text        False\n",
      "metadata    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(data_df.isnull().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db6e450",
   "metadata": {},
   "source": [
    "* It looks like everything was loaded and without any missing values.\n",
    "* Let's examine analytically the content of a line of our dataframe, for ex. the first line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37ab801c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632589828c8b9fca2c3a59e97451fde8fa7d188d\n"
     ]
    }
   ],
   "source": [
    "print(data_df.iloc[0][\"_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5df5486e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A hybrid of genetic algorithm and particle swarm optimization for recurrent network design\n"
     ]
    }
   ],
   "source": [
    "print(data_df.iloc[0][\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd60af0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An evolutionary recurrent network which automates the design of recurrent neural/fuzzy networks using a new evolutionary learning algorithm is proposed in this paper. This new evolutionary learning algorithm is based on a hybrid of genetic algorithm (GA) and particle swarm optimization (PSO), and is thus called HGAPSO. In HGAPSO, individuals in a new generation are created, not only by crossover and mutation operation as in GA, but also by PSO. The concept of elite strategy is adopted in HGAPSO, where the upper-half of the best-performing individuals in a population are regarded as elites. However, instead of being reproduced directly to the next generation, these elites are first enhanced. The group constituted by the elites is regarded as a swarm, and each elite corresponds to a particle within it. In this regard, the elites are enhanced by PSO, an operation which mimics the maturing phenomenon in nature. These enhanced elites constitute half of the population in the new generation, whereas the other half is generated by performing crossover and mutation operation on these enhanced elites. HGAPSO is applied to recurrent neural/fuzzy network design as follows. For recurrent neural network, a fully connected recurrent neural network is designed and applied to a temporal sequence production problem. For recurrent fuzzy network design, a Takagi-Sugeno-Kang-type recurrent fuzzy network is designed and applied to dynamic plant control. The performance of HGAPSO is compared to both GA and PSO in these recurrent networks design problems, demonstrating its superiority.\n"
     ]
    }
   ],
   "source": [
    "print(data_df.iloc[0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a6cd5205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'authors': ['1725986'],\n",
      "  'cited_by': [ '93e1026dd5244e45f6f9ec9e35e9de327b48e4b0',\n",
      "                '870cb11115c8679c7e34f4f2ed5f469badedee37',\n",
      "                '7ee0b2517cbda449d73bacf83c9bb2c96e816da7',\n",
      "                '97ca96b2a60b097bc8e331e526a62c6ce3bb001c',\n",
      "                'f7d4fcd561eda6ce19df70e02b506e3201aa4aa7',\n",
      "                '772f83c311649ad3ca2baf1c7c4de4610315a077',\n",
      "                '0719495764d98886d2436c5f5a6f992104887160',\n",
      "                'a1aa248db86001ea5b68fcf22fa4dc01016442f8',\n",
      "                'a1877adad3b8ca7ca1d4d2344578235754b365b8',\n",
      "... [truncated]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pformat\n",
    "\n",
    "meta = data_df.iloc[0][\"metadata\"]\n",
    "meta_str = pformat(meta, indent=2, width=80)\n",
    "lines = meta_str.splitlines()\n",
    "print(\"\\n\".join(lines[:10]))\n",
    "if len(lines) > 10:\n",
    "    print(\"... [truncated]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d6d2d2",
   "metadata": {},
   "source": [
    "* It appears that in the column `metadata` has some values that could be implemented as their own columns-categories of our dataframe.\n",
    "* Let's make a function that will incorporate these values this way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05c8e503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def update_metadata(df):\n",
    "    df['metadata'] = df['metadata'].apply(lambda x: json.loads(x) if isinstance(x, str) else x)\n",
    "\n",
    "    metadata_df = pd.json_normalize(df['metadata'])\n",
    "    \n",
    "    updated_df = pd.concat([df.drop(columns=['metadata']), metadata_df], axis=1)\n",
    "    \n",
    "    return updated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2539b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df = update_metadata(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63d8bf67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['_id', 'title', 'text', 'authors', 'year', 'cited_by', 'references'], dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b91d698e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>authors</th>\n",
       "      <th>year</th>\n",
       "      <th>cited_by</th>\n",
       "      <th>references</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>632589828c8b9fca2c3a59e97451fde8fa7d188d</td>\n",
       "      <td>A hybrid of genetic algorithm and particle swa...</td>\n",
       "      <td>An evolutionary recurrent network which automa...</td>\n",
       "      <td>[1725986]</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>[93e1026dd5244e45f6f9ec9e35e9de327b48e4b0, 870...</td>\n",
       "      <td>[57fdc130c1b1c3dd1fd11845fe86c60e2d3b7193, 513...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86e87db2dab958f1bd5877dc7d5b8105d6e31e46</td>\n",
       "      <td>A Hybrid EP and SQP for Dynamic Economic Dispa...</td>\n",
       "      <td>Dynamic economic dispatch (DED) is one of the ...</td>\n",
       "      <td>[30728239, 49115828, 1857220, 47952931]</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>[8c6e8ac20aa8507879820a09ed4529d8e903e431, 6b7...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2a047d8c4c2a4825e0f0305294e7da14f8de6fd3</td>\n",
       "      <td>Genetic Fuzzy Systems - Evolutionary Tuning an...</td>\n",
       "      <td>It's not surprisingly when entering this site ...</td>\n",
       "      <td>[1685850, 1699069, 34695695, 1841941]</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>[ac1611bbe12f2dc91dad1d1ded3e618b0b848f21, 333...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>506172b0e0dd4269bdcfe96dda9ea9d8602bbfb6</td>\n",
       "      <td>A modified particle swarm optimizer</td>\n",
       "      <td>In this paper, we introduce a new parameter, c...</td>\n",
       "      <td>[8385459, 4298485]</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>[019d49506e8fac0e964dbc52d1afc495c47df384, f51...</td>\n",
       "      <td>[54acdb67ca083326c34eabdeb59bfdc01c748df0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51317b6082322a96b4570818b7a5ec8b2e330f2f</td>\n",
       "      <td>Identification and control of dynamic systems ...</td>\n",
       "      <td>This paper proposes a recurrent fuzzy neural n...</td>\n",
       "      <td>[34448377, 2062864]</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>[4de9e6412d59169e624df02fc8c4e377a1f8be5d, ac7...</td>\n",
       "      <td>[7e1216cac1ec99b056f4d14f0ca088f3cbb9b120, 8ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>857a8c6c46b0a85ed6019f5830294872f2f1dcf5</td>\n",
       "      <td>Separate face and body selectivity on the fusi...</td>\n",
       "      <td>Recent reports of a high response to bodies in...</td>\n",
       "      <td>[2981413, 2074160, 1931482]</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>[34bf37eb7a34ac4efc57254303f65429a3ccdd85, fde...</td>\n",
       "      <td>[5a06e4c072c85afe71490498e718bf3424faf08c, 3bc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12f107016fd3d062dff88a00d6b0f5f81f00522d</td>\n",
       "      <td>Scheduling for Reduced CPU Energy</td>\n",
       "      <td>The energy usage of computer systems is becomi...</td>\n",
       "      <td>[1800362, 9036495, 1686255, 1753148]</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>[c3ce0da75953dd041152c1757d18647fe05872b2, 33e...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1ae0ac5e13134df7a0d670fc08c2b404f1e3803c</td>\n",
       "      <td>A data mining approach for location prediction...</td>\n",
       "      <td>Mobility prediction is one of the most essenti...</td>\n",
       "      <td>[2108906, 22789555, 1801322, 1796253]</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>[f1f25228e0285e615b84a150dec2279785bc7dc6, 8e8...</td>\n",
       "      <td>[073bc173609570544a63770d0ce51ce17dd079e5, ac3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7d3c9c4064b588d5d8c7c0cb398118aac239c71b</td>\n",
       "      <td>$\\mathsf {pSCAN}$ : Fast and Exact Structural ...</td>\n",
       "      <td>We study the problem of structural graph clust...</td>\n",
       "      <td>[38736958, 35660624, 36838704, 19262604, 47569...</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[dd31b94077f656630348f810607308204d5fe013, 680...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>305c45fb798afdad9e6d34505b4195fa37c2ee4f</td>\n",
       "      <td>Synthesis, properties, and applications of iro...</td>\n",
       "      <td>Iron, the most ubiquitous of the transition me...</td>\n",
       "      <td>[5701357]</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>[82b17ab50e8d80c81f28c22e43631fa7ec6cbef2, 649...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        _id  \\\n",
       "0  632589828c8b9fca2c3a59e97451fde8fa7d188d   \n",
       "1  86e87db2dab958f1bd5877dc7d5b8105d6e31e46   \n",
       "2  2a047d8c4c2a4825e0f0305294e7da14f8de6fd3   \n",
       "3  506172b0e0dd4269bdcfe96dda9ea9d8602bbfb6   \n",
       "4  51317b6082322a96b4570818b7a5ec8b2e330f2f   \n",
       "5  857a8c6c46b0a85ed6019f5830294872f2f1dcf5   \n",
       "6  12f107016fd3d062dff88a00d6b0f5f81f00522d   \n",
       "7  1ae0ac5e13134df7a0d670fc08c2b404f1e3803c   \n",
       "8  7d3c9c4064b588d5d8c7c0cb398118aac239c71b   \n",
       "9  305c45fb798afdad9e6d34505b4195fa37c2ee4f   \n",
       "\n",
       "                                               title  \\\n",
       "0  A hybrid of genetic algorithm and particle swa...   \n",
       "1  A Hybrid EP and SQP for Dynamic Economic Dispa...   \n",
       "2  Genetic Fuzzy Systems - Evolutionary Tuning an...   \n",
       "3                A modified particle swarm optimizer   \n",
       "4  Identification and control of dynamic systems ...   \n",
       "5  Separate face and body selectivity on the fusi...   \n",
       "6                  Scheduling for Reduced CPU Energy   \n",
       "7  A data mining approach for location prediction...   \n",
       "8  $\\mathsf {pSCAN}$ : Fast and Exact Structural ...   \n",
       "9  Synthesis, properties, and applications of iro...   \n",
       "\n",
       "                                                text  \\\n",
       "0  An evolutionary recurrent network which automa...   \n",
       "1  Dynamic economic dispatch (DED) is one of the ...   \n",
       "2  It's not surprisingly when entering this site ...   \n",
       "3  In this paper, we introduce a new parameter, c...   \n",
       "4  This paper proposes a recurrent fuzzy neural n...   \n",
       "5  Recent reports of a high response to bodies in...   \n",
       "6  The energy usage of computer systems is becomi...   \n",
       "7  Mobility prediction is one of the most essenti...   \n",
       "8  We study the problem of structural graph clust...   \n",
       "9  Iron, the most ubiquitous of the transition me...   \n",
       "\n",
       "                                             authors    year  \\\n",
       "0                                          [1725986]  2004.0   \n",
       "1            [30728239, 49115828, 1857220, 47952931]  2002.0   \n",
       "2              [1685850, 1699069, 34695695, 1841941]  2001.0   \n",
       "3                                 [8385459, 4298485]  1998.0   \n",
       "4                                [34448377, 2062864]  2000.0   \n",
       "5                        [2981413, 2074160, 1931482]  2005.0   \n",
       "6               [1800362, 9036495, 1686255, 1753148]  1994.0   \n",
       "7              [2108906, 22789555, 1801322, 1796253]  2005.0   \n",
       "8  [38736958, 35660624, 36838704, 19262604, 47569...  2017.0   \n",
       "9                                          [5701357]  2005.0   \n",
       "\n",
       "                                            cited_by  \\\n",
       "0  [93e1026dd5244e45f6f9ec9e35e9de327b48e4b0, 870...   \n",
       "1  [8c6e8ac20aa8507879820a09ed4529d8e903e431, 6b7...   \n",
       "2  [ac1611bbe12f2dc91dad1d1ded3e618b0b848f21, 333...   \n",
       "3  [019d49506e8fac0e964dbc52d1afc495c47df384, f51...   \n",
       "4  [4de9e6412d59169e624df02fc8c4e377a1f8be5d, ac7...   \n",
       "5  [34bf37eb7a34ac4efc57254303f65429a3ccdd85, fde...   \n",
       "6  [c3ce0da75953dd041152c1757d18647fe05872b2, 33e...   \n",
       "7  [f1f25228e0285e615b84a150dec2279785bc7dc6, 8e8...   \n",
       "8                                                 []   \n",
       "9  [82b17ab50e8d80c81f28c22e43631fa7ec6cbef2, 649...   \n",
       "\n",
       "                                          references  \n",
       "0  [57fdc130c1b1c3dd1fd11845fe86c60e2d3b7193, 513...  \n",
       "1                                                 []  \n",
       "2                                                 []  \n",
       "3         [54acdb67ca083326c34eabdeb59bfdc01c748df0]  \n",
       "4  [7e1216cac1ec99b056f4d14f0ca088f3cbb9b120, 8ad...  \n",
       "5  [5a06e4c072c85afe71490498e718bf3424faf08c, 3bc...  \n",
       "6                                                 []  \n",
       "7  [073bc173609570544a63770d0ce51ce17dd079e5, ac3...  \n",
       "8  [dd31b94077f656630348f810607308204d5fe013, 680...  \n",
       "9                                                 []  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3855b696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_id           False\n",
      "title         False\n",
      "text          False\n",
      "authors       False\n",
      "year           True\n",
      "cited_by      False\n",
      "references    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(updated_df.isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a37418a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_id            0\n",
      "title          0\n",
      "text           0\n",
      "authors        0\n",
      "year          72\n",
      "cited_by       0\n",
      "references     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(updated_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce9b7b8",
   "metadata": {},
   "source": [
    "* It seems that years are stored as decimals and that some years are missing.\n",
    "* We will turn the null years into zeros and all year values into integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6f3ada68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8936\\2782452430.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  updated_df['year'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "updated_df['year'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "37a60239",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df['year'] = updated_df['year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6c51d559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_id           0\n",
      "title         0\n",
      "text          0\n",
      "authors       0\n",
      "year          0\n",
      "cited_by      0\n",
      "references    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(updated_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2d5f4347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_id           object\n",
       "title         object\n",
       "text          object\n",
       "authors       object\n",
       "year           int32\n",
       "cited_by      object\n",
       "references    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fbe936",
   "metadata": {},
   "source": [
    "* It appears that some columns don't offer interesting information, they just contain codes, for example the authors colum.\n",
    "* We will modify their values to be, instead of lists of codes, just a number that states the length of each list.\n",
    "* For example if a value of the authors column is 2 it means there were 2 authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e4f24557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated DataFrame with list lengths:\n",
      "                                        _id  \\\n",
      "0  632589828c8b9fca2c3a59e97451fde8fa7d188d   \n",
      "1  86e87db2dab958f1bd5877dc7d5b8105d6e31e46   \n",
      "2  2a047d8c4c2a4825e0f0305294e7da14f8de6fd3   \n",
      "3  506172b0e0dd4269bdcfe96dda9ea9d8602bbfb6   \n",
      "4  51317b6082322a96b4570818b7a5ec8b2e330f2f   \n",
      "\n",
      "                                               title  \\\n",
      "0  A hybrid of genetic algorithm and particle swa...   \n",
      "1  A Hybrid EP and SQP for Dynamic Economic Dispa...   \n",
      "2  Genetic Fuzzy Systems - Evolutionary Tuning an...   \n",
      "3                A modified particle swarm optimizer   \n",
      "4  Identification and control of dynamic systems ...   \n",
      "\n",
      "                                                text  authors  year  cited_by  \\\n",
      "0  An evolutionary recurrent network which automa...        1  2004       432   \n",
      "1  Dynamic economic dispatch (DED) is one of the ...        4  2002       169   \n",
      "2  It's not surprisingly when entering this site ...        4  2001       521   \n",
      "3  In this paper, we introduce a new parameter, c...        2  1998      3659   \n",
      "4  This paper proposes a recurrent fuzzy neural n...        2  2000       318   \n",
      "\n",
      "   references  \n",
      "0          10  \n",
      "1           0  \n",
      "2           0  \n",
      "3           1  \n",
      "4          10  \n"
     ]
    }
   ],
   "source": [
    "columns_to_count = ['authors', 'cited_by', 'references']\n",
    "\n",
    "for col in columns_to_count:\n",
    "    updated_df[col] = updated_df[col].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "\n",
    "print(\"Updated DataFrame with list lengths:\")\n",
    "print(updated_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7becb46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_id              0\n",
      "title            0\n",
      "text             0\n",
      "authors        567\n",
      "year            72\n",
      "cited_by      2649\n",
      "references    1153\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print((updated_df == 0).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332dcfc5",
   "metadata": {},
   "source": [
    "### Text Cleaning\n",
    "We will modify our dataframe so that it's in a form appropriate to be used ElasticSearch (a.k.a. json). We want to do the following transformations into our text values:\n",
    "1. **Tokenization**: Split each text into tokens.\n",
    "\n",
    "2. **Lowercasing**: Turn all words into lowercase.\n",
    "\n",
    "3. **Removal of Stop Words**: Remove common words that don't offer much information.\n",
    "\n",
    "4. **Stemming**: Trim words into their core form.\n",
    "\n",
    "5. **Save**: Save updated data into a json file.  \n",
    "\n",
    "In more detail:  \n",
    "\n",
    "* We'll use the library `NLTK (Natural Language Toolkit)` which is used for processing and analyzing natural language in Python.\n",
    "\n",
    "* The tokenization will happen with the function `word_tokenize`.\n",
    "\n",
    "* Punctuation marks and words with non alphabetical symbols will be removed with the condition `isalpha()`.\n",
    "\n",
    "* Stop words will be removed with `stopwords` of `nltk.corpus`.\n",
    "\n",
    "* We'll do a **grammatical stemming** with the use of the `PorterStemmer` algorithm (ex. \"running\" → \"run\"), and a **logical stemming** (ex. \"better\" → \"good\") with `WordNetLemmatizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "365c548d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "def clean_text(text):\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stemmer = PorterStemmer()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "\n",
    "    # tokenization\n",
    "    words = word_tokenize(text)\n",
    "    # lowercasing and removing non-alphabetic words\n",
    "    words = [word.lower() for word in words if word.isalpha()]\n",
    "    # stop words removal\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    # Stemming/Lemmatization\n",
    "    words = [lemmatizer.lemmatize(stemmer.stem(word)) for word in words]\n",
    "    # joining the words back into a cleaned text\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e8a51e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text cleaning and normalization complete. Data saved as 'cleaned_data.json'.\n"
     ]
    }
   ],
   "source": [
    "cleaned_df = updated_df.copy(deep=False)\n",
    "\n",
    "cleaned_df = cleaned_df.assign(\n",
    "    title=lambda x: x['title'].apply(clean_text),\n",
    "    text=lambda x: x['text'].apply(clean_text)\n",
    ")\n",
    "\n",
    "cleaned_df.to_json('cleaned_data.json', orient='records', lines=True)\n",
    "\n",
    "print(\"Text cleaning and normalization complete. Data saved as 'cleaned_data.json'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24716670",
   "metadata": {},
   "source": [
    "* Let's check how our data was transformed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "395d3e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>authors</th>\n",
       "      <th>year</th>\n",
       "      <th>cited_by</th>\n",
       "      <th>references</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>632589828c8b9fca2c3a59e97451fde8fa7d188d</td>\n",
       "      <td>hybrid genet algorithm particl swarm optim rec...</td>\n",
       "      <td>evolutionari recurr network autom design recur...</td>\n",
       "      <td>1</td>\n",
       "      <td>2004</td>\n",
       "      <td>432</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86e87db2dab958f1bd5877dc7d5b8105d6e31e46</td>\n",
       "      <td>hybrid ep sqp dynam econom dispatch nonsmooth ...</td>\n",
       "      <td>dynam econom dispatch ded one main function po...</td>\n",
       "      <td>4</td>\n",
       "      <td>2002</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2a047d8c4c2a4825e0f0305294e7da14f8de6fd3</td>\n",
       "      <td>genet fuzzi system evolutionari tune learn fuz...</td>\n",
       "      <td>surprisingli enter site get book one popular b...</td>\n",
       "      <td>4</td>\n",
       "      <td>2001</td>\n",
       "      <td>521</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        _id  \\\n",
       "0  632589828c8b9fca2c3a59e97451fde8fa7d188d   \n",
       "1  86e87db2dab958f1bd5877dc7d5b8105d6e31e46   \n",
       "2  2a047d8c4c2a4825e0f0305294e7da14f8de6fd3   \n",
       "\n",
       "                                               title  \\\n",
       "0  hybrid genet algorithm particl swarm optim rec...   \n",
       "1  hybrid ep sqp dynam econom dispatch nonsmooth ...   \n",
       "2  genet fuzzi system evolutionari tune learn fuz...   \n",
       "\n",
       "                                                text  authors  year  cited_by  \\\n",
       "0  evolutionari recurr network autom design recur...        1  2004       432   \n",
       "1  dynam econom dispatch ded one main function po...        4  2002       169   \n",
       "2  surprisingli enter site get book one popular b...        4  2001       521   \n",
       "\n",
       "   references  \n",
       "0          10  \n",
       "1           0  \n",
       "2           0  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "29568c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_id           object\n",
       "title         object\n",
       "text          object\n",
       "authors        int64\n",
       "year           int32\n",
       "cited_by       int64\n",
       "references     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e9d152bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df['title'] = updated_df['title'].astype(str)\n",
    "updated_df['text'] = updated_df['text'].astype(str)\n",
    "cleaned_df['title'] = cleaned_df['title'].astype(str)\n",
    "cleaned_df['text'] = cleaned_df['text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "247864ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title before: \"A hybrid of genetic algorithm and particle swarm optimization for recurrent network design\".\n",
      "Title after: \"hybrid genet algorithm particl swarm optim recurr network design\".\n",
      "-----------------------------------------------\n",
      "Text before: \"An evolutionary recurrent network which automates the design of recurrent neural/fuzzy networks using a new evolutionary learning algorithm is proposed in this paper. This new evolutionary learning algorithm is based on a hybrid of genetic algorithm (GA) and particle swarm optimization (PSO), and is thus called HGAPSO. In HGAPSO, individuals in a new generation are created, not only by crossover and mutation operation as in GA, but also by PSO. The concept of elite strategy is adopted in HGAPSO, where the upper-half of the best-performing individuals in a population are regarded as elites. However, instead of being reproduced directly to the next generation, these elites are first enhanced. The group constituted by the elites is regarded as a swarm, and each elite corresponds to a particle within it. In this regard, the elites are enhanced by PSO, an operation which mimics the maturing phenomenon in nature. These enhanced elites constitute half of the population in the new generation, whereas the other half is generated by performing crossover and mutation operation on these enhanced elites. HGAPSO is applied to recurrent neural/fuzzy network design as follows. For recurrent neural network, a fully connected recurrent neural network is designed and applied to a temporal sequence production problem. For recurrent fuzzy network design, a Takagi-Sugeno-Kang-type recurrent fuzzy network is designed and applied to dynamic plant control. The performance of HGAPSO is compared to both GA and PSO in these recurrent networks design problems, demonstrating its superiority.\".\n",
      "Text after: \"evolutionari recurr network autom design recurr network use new evolutionari learn algorithm propos paper new evolutionari learn algorithm base hybrid genet algorithm ga particl swarm optim pso thu call hgapso hgapso individu new gener creat crossov mutat oper ga also pso concept elit strategi adopt hgapso individu popul regard elit howev instead reproduc directli next gener elit first enhanc group constitut elit regard swarm elit correspond particl within regard elit enhanc pso oper mimic matur phenomenon natur enhanc elit constitut half popul new gener wherea half gener perform crossov mutat oper enhanc elit hgapso appli recurr network design follow recurr neural network fulli connect recurr neural network design appli tempor sequenc product problem recurr fuzzi network design recurr fuzzi network design appli dynam plant control perform hgapso compar ga pso recurr network design problem demonstr superior\".\n"
     ]
    }
   ],
   "source": [
    "print(f\"Title before: \\\"{updated_df.iloc[0][\"title\"]}\\\".\")\n",
    "print(f\"Title after: \\\"{cleaned_df.iloc[0][\"title\"]}\\\".\")\n",
    "print(f\"-----------------------------------------------\")\n",
    "print(f\"Text before: \\\"{updated_df.iloc[0][\"text\"]}\\\".\")\n",
    "print(f\"Text after: \\\"{cleaned_df.iloc[0][\"text\"]}\\\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d3ca68",
   "metadata": {},
   "source": [
    "* We can see that our goal was achieved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102e6a16",
   "metadata": {},
   "source": [
    "## Index creation with the use of ElasticSearch.  \n",
    "\n",
    "### Connection with Elasticsearch  \n",
    "\n",
    "* Elasticsearch is a distributed search engine, and a tool for real time data analysis, which is used for storing, searching and analyzing large amounts of data with speed and effectiveness.\n",
    "* Let's download it if it hasn't already been downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4ee3b7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: elasticsearch in c:\\users\\user\\anaconda3\\lib\\site-packages (9.0.1)\n",
      "Requirement already satisfied: elastic-transport<9,>=8.15.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from elasticsearch) (8.17.1)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\user\\anaconda3\\lib\\site-packages (from elasticsearch) (2.9.0.post0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\anaconda3\\lib\\site-packages (from elasticsearch) (4.11.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from elastic-transport<9,>=8.15.1->elasticsearch) (2.2.3)\n",
      "Requirement already satisfied: certifi in c:\\users\\user\\anaconda3\\lib\\site-packages (from elastic-transport<9,>=8.15.1->elasticsearch) (2024.8.30)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from python-dateutil->elasticsearch) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff47746",
   "metadata": {},
   "source": [
    "* Now, we'll import the modules we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "420d8505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import bulk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ac8c6a",
   "metadata": {},
   "source": [
    "* We'll use connection credentials (they aren't the same for everyone) to check if elasticsearch is running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7086eb2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\" : \"DESKTOP-T3AQS4C\",\n",
      "  \"cluster_name\" : \"elasticsearch\",\n",
      "  \"cluster_uuid\" : \"83WbcL3bR6O512OaxxoHvQ\",\n",
      "  \"version\" : {\n",
      "    \"number\" : \"9.0.1\",\n",
      "    \"build_flavor\" : \"default\",\n",
      "    \"build_type\" : \"zip\",\n",
      "    \"build_hash\" : \"73f7594ea00db50aa7e941e151a5b3985f01e364\",\n",
      "    \"build_date\" : \"2025-04-30T10:07:41.393025990Z\",\n",
      "    \"build_snapshot\" : false,\n",
      "    \"lucene_version\" : \"10.1.0\",\n",
      "    \"minimum_wire_compatibility_version\" : \"8.18.0\",\n",
      "    \"minimum_index_compatibility_version\" : \"8.0.0\"\n",
      "  },\n",
      "  \"tagline\" : \"You Know, for Search\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100   539  100   539    0     0  70744      0 --:--:-- --:--:-- --:--:-- 77000\n"
     ]
    }
   ],
   "source": [
    "!curl -u elastic:9uAH3wr_ZKMvFXJOCTSc http://localhost:9200/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d85d4fe",
   "metadata": {},
   "source": [
    "* And, finally, we'll create the client instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2d827ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Elasticsearch(\n",
    "    \"http://localhost:9200\",\n",
    "    basic_auth=(\"elastic\", \"9uAH3wr_ZKMvFXJOCTSc\"),\n",
    "    request_timeout=1000000  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28657c8f",
   "metadata": {},
   "source": [
    "### Index Creation\n",
    "\n",
    "We will need to choose an appropriate **Analyzer** and a **similarity function**. Let's look at what each of these are:\n",
    "  \n",
    "   \n",
    "`Analyzer`\n",
    "* An analyzer is like a text cleaner and organizer.\n",
    "\n",
    "* It ensures that all variations of a word (like \"run\", \"running\", \"ran\") are treated as the same word, and that common words are ignored.\n",
    "\n",
    "* Even though our texts are currently preprocessed (with clean_text), we will still need an analyzer.\n",
    "\n",
    "* This is because the texts in the index may be simplified, but our queries need to match them.\n",
    "   \n",
    "`Similarity Function`\n",
    "\n",
    "* The similarity function is the way the system measures how similar/relevant a sentence/text is to a query.\n",
    "\n",
    "* With the appropriate similarity function, we can rank the results based on how well they match.\n",
    "\n",
    "* We will use the **Vector Space Model (VSM)**, which represents documents and queries as vectors in a multidimensional space.\n",
    "\n",
    "* In this model, similarity is typically computed based on **TF-IDF (term frequency-inverse document frequency)** weighting, which gives more importance to words that appear frequently in a document but rarely across the collection.\n",
    "\n",
    "* The vector space model is simple, efficient, and widely used for information retrieval tasks, and allows us to compute similarity in mathematical terms (e.g. inner product), making search more accurate and easily scalable.   \n",
    "\n",
    "More Specifically:\n",
    "\n",
    "`Vector Space Model (TF-IDF)`\n",
    "\n",
    "* Calculates the **meaning of the terms** in the documents.\n",
    "* Assigns **a higher weight to terms** that are **less common** in the entirety of all documents.\n",
    "* Their similarity is calculated as:\n",
    "\n",
    "$$\n",
    "\\text{Similarity} = \\text{tf} \\times \\text{idf} \\times \\text{norm}\n",
    "$$\n",
    "\n",
    "- **tf**: Square root of the frequency of the term (how many times does the term appear in the document).\n",
    "- **idf**: Logarithmic pointer of the rarity of the terms in all documents.\n",
    "- **norm**: Factor of normalization of lenght, to avoid bigger texts having a bigger impact.\n",
    "\n",
    "We'll firstly create an empty index with a defined structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d43aff3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True})"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.indices.delete(index=\"ir_2025\") #empty it in case it already exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ab8b0fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index created successfully!\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch, helpers\n",
    "import pandas as pd\n",
    "\n",
    "vsm_optimized_mapping = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0, \n",
    "        \"similarity\": {\n",
    "            \"scripted_tfidf\": {\n",
    "                \"type\": \"scripted\",\n",
    "                \"script\": {\n",
    "                    \"source\": \"\"\"\n",
    "                        double tf = Math.sqrt(doc.freq);\n",
    "                        double idf = Math.log((field.docCount + 1.0) / (term.docFreq + 1.0)) + 1.0;\n",
    "                        double norm = 1 / Math.sqrt(doc.length);\n",
    "                        return query.boost * tf * idf * norm;\n",
    "                    \"\"\"\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"analysis\": {\n",
    "            \"analyzer\": {\n",
    "                \"custom_english\": {  \n",
    "                    \"type\": \"english\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"title\": {\n",
    "                \"type\": \"text\",\n",
    "                \"copy_to\": \"allContent\",\n",
    "                \"analyzer\": \"custom_english\",\n",
    "                \"similarity\": \"scripted_tfidf\"\n",
    "            },\n",
    "            \"text\": {\n",
    "                \"type\": \"text\",\n",
    "                \"copy_to\": \"allContent\",\n",
    "                \"analyzer\": \"custom_english\",\n",
    "                \"similarity\": \"scripted_tfidf\"\n",
    "            },\n",
    "            \"authors\": {\n",
    "                \"type\": \"integer\",\n",
    "                \"copy_to\": \"allContent\"\n",
    "            },\n",
    "            \"cited_by\": {\n",
    "                \"type\": \"integer\",\n",
    "                \"copy_to\": \"allContent\"\n",
    "            },\n",
    "            \"references\": {\n",
    "                \"type\": \"integer\",\n",
    "                \"copy_to\": \"allContent\"\n",
    "            },\n",
    "            \"year\": {\n",
    "                \"type\": \"integer\",\n",
    "                \"copy_to\": \"allContent\"\n",
    "            },\n",
    "            \"allContent\": {\n",
    "                \"type\": \"text\",\n",
    "                \"analyzer\": \"custom_english\",\n",
    "                \"similarity\": \"scripted_tfidf\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "try:\n",
    "    client.indices.create(index='ir_2025', body=vsm_optimized_mapping, master_timeout='2m')\n",
    "    print(\"Index created successfully!\")\n",
    "except Exception as e:\n",
    "    print(\"Error creating index:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8aaed37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed batch 1 successfully\n",
      "Indexed batch 2 successfully\n",
      "Indexed batch 3 successfully\n",
      "Indexed batch 4 successfully\n",
      "Indexed batch 5 successfully\n",
      "Indexed batch 6 successfully\n",
      "Indexed batch 7 successfully\n",
      "Indexed batch 8 successfully\n",
      "Indexed batch 9 successfully\n",
      "Indexed batch 10 successfully\n",
      "Indexed batch 11 successfully\n",
      "Indexed batch 12 successfully\n",
      "Indexed batch 13 successfully\n",
      "Indexed batch 14 successfully\n",
      "Indexed batch 15 successfully\n",
      "Indexed batch 16 successfully\n",
      "Indexed batch 17 successfully\n",
      "Indexed batch 18 successfully\n",
      "Indexed batch 19 successfully\n",
      "Indexed batch 20 successfully\n",
      "Indexed batch 21 successfully\n",
      "Indexed batch 22 successfully\n",
      "Indexed batch 23 successfully\n",
      "Indexed batch 24 successfully\n",
      "Indexed batch 25 successfully\n",
      "Indexed batch 26 successfully\n",
      "Indexed batch 27 successfully\n",
      "Indexed batch 28 successfully\n",
      "Indexed batch 29 successfully\n",
      "Indexed batch 30 successfully\n",
      "Indexed batch 31 successfully\n",
      "Indexed batch 32 successfully\n",
      "Indexed batch 33 successfully\n",
      "Indexed batch 34 successfully\n",
      "Indexed batch 35 successfully\n",
      "Indexed batch 36 successfully\n",
      "Indexed batch 37 successfully\n",
      "Indexed batch 38 successfully\n",
      "Indexed batch 39 successfully\n",
      "Indexed batch 40 successfully\n",
      "Indexed batch 41 successfully\n",
      "Indexed batch 42 successfully\n",
      "Indexed batch 43 successfully\n",
      "Indexed batch 44 successfully\n",
      "Indexed batch 45 successfully\n",
      "Indexed batch 46 successfully\n",
      "Indexed batch 47 successfully\n",
      "Indexed batch 48 successfully\n",
      "Indexed batch 49 successfully\n",
      "Indexed batch 50 successfully\n",
      "Indexed batch 51 successfully\n",
      "Indexed batch 52 successfully\n"
     ]
    }
   ],
   "source": [
    "def generate_data(df):\n",
    "    for index, row in df.iterrows():\n",
    "        yield {\n",
    "            \"_index\": \"ir_2025\",\n",
    "            \"_id\": row['_id'],  \n",
    "            \"_source\": {\n",
    "                \"title\": row['title'],\n",
    "                \"text\": row['text'],\n",
    "                \"authors\": row['authors'],\n",
    "                \"cited_by\": row['cited_by'],\n",
    "                \"references\": row['references'],\n",
    "                \"year\": row['year'],\n",
    "                \"allContent\": f\"{row['title']} {row['text']} {row['authors']} {row['cited_by']} {row['references']} {row['year']}\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "def bulk_index_data(df, batch_size=500):\n",
    "    try:\n",
    "        for i in range(0, len(df), batch_size):\n",
    "            chunk = df.iloc[i:i+batch_size]\n",
    "            bulk(client.options(request_timeout=300), generate_data(chunk))\n",
    "            print(f\"Indexed batch {i//batch_size + 1} successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during bulk indexing at batch {i//batch_size + 1}:\", e)\n",
    "\n",
    "bulk_index_data(cleaned_df, batch_size=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bc2434",
   "metadata": {},
   "source": [
    "`Results`\n",
    "* Generally, to calculate the **number of batches**, we use the formula:\n",
    "$$\n",
    "\\text{Number of batches} = \\lceil \\frac{\\text{Total Lines}}{\\text{Size of batch}} \\rceil\n",
    "$$\n",
    "* And our data is:\n",
    "$$\n",
    "\\text{Total Lines: } 25,657 \\quad | \\quad \\text{Size of batch: } 500\n",
    "$$\n",
    "* So we must get:\n",
    "$$\n",
    "\\text{Size of batches} = \\lceil \\frac{25657}{500} \\rceil\n",
    "$$\n",
    "$$\n",
    "\\text{Size of batches} = \\lceil 51.314 \\rceil = 52\n",
    "$$\n",
    "\n",
    "* So, **our index was created successfully**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce80cce",
   "metadata": {},
   "source": [
    "`Concerning allContent`\n",
    "* The addition of `\"copy_to\": \"allContent\"` makes the search more efficient. \n",
    "* It is useful for the consistency of results in case there's a search for many fields simultaneously.\n",
    "\n",
    "`Concerning Shards`  \n",
    "* Each index in ElasticSearch consists of smaller ones called shards. \n",
    "* Each shard has its own index and can be hosted in a unique node in a cluster.\n",
    "* Our dataframe has 25657 rows.\n",
    "* Since each file takes up 1KB of space then we have almost 25KB.\n",
    "* ElasticSearch can manage 50 GB effectively. In comparisson 25ΚΒ is little, so one shard shall be enough."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6491a9",
   "metadata": {},
   "source": [
    "* Let's check a few things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e6b62ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index exists!\n"
     ]
    }
   ],
   "source": [
    "if client.indices.exists(index=\"ir_2025\"):\n",
    "    print(\"Index exists!\")\n",
    "else:\n",
    "    print(\"Index not found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6f8877ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ir_2025': {'aliases': {}, 'mappings': {'properties': {'allContent': {'type': 'text', 'analyzer': 'custom_english', 'similarity': 'scripted_tfidf'}, 'authors': {'type': 'integer', 'copy_to': ['allContent']}, 'cited_by': {'type': 'integer', 'copy_to': ['allContent']}, 'references': {'type': 'integer', 'copy_to': ['allContent']}, 'text': {'type': 'text', 'copy_to': ['allContent'], 'analyzer': 'custom_english', 'similarity': 'scripted_tfidf'}, 'title': {'type': 'text', 'copy_to': ['allContent'], 'analyzer': 'custom_english', 'similarity': 'scripted_tfidf'}, 'year': {'type': 'integer', 'copy_to': ['allContent']}}}, 'settings': {'index': {'routing': {'allocation': {'include': {'_tier_preference': 'data_content'}}}, 'number_of_shards': '1', 'provided_name': 'ir_2025', 'similarity': {'scripted_tfidf': {'type': 'scripted', 'script': {'source': '\\n                        double tf = Math.sqrt(doc.freq);\\n                        double idf = Math.log((field.docCount + 1.0) / (term.docFreq + 1.0)) + 1.0;\\n                        double norm = 1 / Math.sqrt(doc.length);\\n                        return query.boost * tf * idf * norm;\\n                    '}}}, 'creation_date': '1750849874165', 'analysis': {'analyzer': {'custom_english': {'type': 'english'}}}, 'number_of_replicas': '0', 'uuid': 'kODsFQCzQKWfz6feTQYTmQ', 'version': {'created': '9009000'}}}}}\n"
     ]
    }
   ],
   "source": [
    "response = client.indices.get(index=\"ir_2025\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f1b0adc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ir_2025': {'mappings': {'properties': {'allContent': {'type': 'text', 'analyzer': 'custom_english', 'similarity': 'scripted_tfidf'}, 'authors': {'type': 'integer', 'copy_to': ['allContent']}, 'cited_by': {'type': 'integer', 'copy_to': ['allContent']}, 'references': {'type': 'integer', 'copy_to': ['allContent']}, 'text': {'type': 'text', 'copy_to': ['allContent'], 'analyzer': 'custom_english', 'similarity': 'scripted_tfidf'}, 'title': {'type': 'text', 'copy_to': ['allContent'], 'analyzer': 'custom_english', 'similarity': 'scripted_tfidf'}, 'year': {'type': 'integer', 'copy_to': ['allContent']}}}}}\n"
     ]
    }
   ],
   "source": [
    "mapping = client.indices.get_mapping(index=\"ir_2025\")\n",
    "print(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ca089b",
   "metadata": {},
   "source": [
    "## Implementation of the Queries  \n",
    "At this point we will execute queries on our index and we'll collect the answers of our search machine. We will use the queries that exist in the file `scidocs`. We'll keept the k first retreved texts, with `k = 20, 30, 50`.\n",
    "*  Let's firstly load the queries and create a function that will make a singular query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "75f1eb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = []\n",
    "with open('./scidocs/queries.jsonl', \"r\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        queries.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6720bd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_document(query_text, size=20):\n",
    "    response = client.search(\n",
    "        index=\"ir_2025\",\n",
    "        body={\n",
    "            \"query\": {\n",
    "                \"match\": {\n",
    "                    \"allContent\": query_text\n",
    "                }\n",
    "            },\n",
    "            \"size\": size\n",
    "        }\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdb0df1",
   "metadata": {},
   "source": [
    "* Time to create structures in which we will store the answers for all queries, as well as for the various k.  \n",
    "* We will also include the cases k = 5, 10, and 15 for calculations that we will do in part 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fcdd8004",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for q in queries:\n",
    "    query_text = q.get(\"text\", \"\")\n",
    "    query_id = q.get(\"_id\", \"\")\n",
    "    if not query_text:\n",
    "        continue\n",
    "    \n",
    "    response = search_document(query_text, size=1000)  \n",
    "    hits = response['hits']['hits']\n",
    "    \n",
    "    if not hits:\n",
    "        print(\"  No results found.\\n\")\n",
    "        continue\n",
    "    \n",
    "    results_list = []\n",
    "    for hit in hits:\n",
    "        id = hit['_id']\n",
    "        source = hit['_source']\n",
    "        score = hit['_score']\n",
    "        title = source.get('title', 'N/A')\n",
    "        text = source.get('text', 'N/A')\n",
    "        results_list.append((id, title, text, score))\n",
    "    \n",
    "    data.append({\n",
    "        \"query_id\": query_id,\n",
    "        \"query\": query_text,\n",
    "        \"results\": results_list\n",
    "    })\n",
    "dfs_all = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59411f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = [5, 10, 15, 20, 30, 50]\n",
    "results = {}\n",
    "dfs = {}\n",
    "for k in k_values:\n",
    "    data = []\n",
    "    \n",
    "    for q in queries:\n",
    "        query_text = q.get(\"text\", \"\")\n",
    "        query_id = q.get(\"_id\", \"\")\n",
    "        if not query_text:\n",
    "            continue\n",
    "        \n",
    "        response = search_document(query_text, size=k)\n",
    "        hits = response['hits']['hits']\n",
    "        \n",
    "        if not hits:\n",
    "            print(\"No results found.\\n\")\n",
    "            continue\n",
    "        \n",
    "        results_list = []\n",
    "        for hit in hits:\n",
    "            id = hit['_id']\n",
    "            source = hit['_source']\n",
    "            score = hit['_score']\n",
    "            title = source.get('title', 'N/A')\n",
    "            text = source.get('text', 'N/A')\n",
    "            results_list.append((id, title, text, score))\n",
    "        \n",
    "        data.append({\n",
    "            \"query_id\": query_id,\n",
    "            \"query\": query_text,\n",
    "            \"results\": results_list\n",
    "        })\n",
    "    \n",
    "    dfs[k] = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16975518",
   "metadata": {},
   "source": [
    "* We see that there were answers to our queries.  \n",
    "* `dfs` is a dictionary where each key is one of the k values (5, 10, 15, 20, 30, 50) and each value is a pandas DataFrame.  \n",
    "* Each DataFrame has three columns:  \n",
    "  * **query_id** — the id of the search (query)  \n",
    "  * **query** — the text of the search (query) as a string  \n",
    "  * **results** — a list of tuples (title, score), where each tuple represents a search result and its relevance score.  \n",
    "* Each row corresponds to a single search, so each row stores all the top-k results of the search in a list in the `results` column.  \n",
    "* Let's examine the contents of this dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "15642d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[20].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "156e25bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[30].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5ac2a8fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[50].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "cc2cdf6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1000.000000\n",
       "mean       19.991000\n",
       "std         0.284605\n",
       "min        11.000000\n",
       "25%        20.000000\n",
       "50%        20.000000\n",
       "75%        20.000000\n",
       "max        20.000000\n",
       "Name: results, dtype: float64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[20]['results'].apply(len).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8afe2b7",
   "metadata": {},
   "source": [
    "* **count**: 1000.0 -> There are 1000 queries in the DataFrame.\n",
    "\n",
    "* **mean**: 19.9 -> On average, each query returned about 19.9 results.\n",
    "\n",
    "* **std**: 0.284605 -> The standard deviation is 0.28, meaning there is little variation in the number of results per query.\n",
    "\n",
    "* **min**: 11, **25%, 50%, 75%, max** all equal 20 -> The number of results per query is not exactly 20 for all queries, but it is for most of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6aea6520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1000.000000\n",
       "mean       29.981000\n",
       "std         0.600833\n",
       "min        11.000000\n",
       "25%        30.000000\n",
       "50%        30.000000\n",
       "75%        30.000000\n",
       "max        30.000000\n",
       "Name: results, dtype: float64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[30]['results'].apply(len).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238f48c2",
   "metadata": {},
   "source": [
    "* **count**: 1000.000000 — There are 1000 queries in the DataFrame.\n",
    "\n",
    "* **mean**: 29.981000 — On average, each query returned about 29.98 results.\n",
    "\n",
    "* **std**: 0.600833 — The standard deviation is about 0.6, indicating little variation in the number of results per query, though slightly more than for k=20.\n",
    "\n",
    "* **min:** 11, **25%: 30, 50%: 30, 75%:** 30, **max:** 30 — The minimum number of results was 11, while 25%, 50%, and 75% of the queries returned 30 results, with a maximum of 30. This shows that most queries returned the full 30 results, but some had fewer (less than 30)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "174138c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1000.000000\n",
       "mean       49.961000\n",
       "std         1.233288\n",
       "min        11.000000\n",
       "25%        50.000000\n",
       "50%        50.000000\n",
       "75%        50.000000\n",
       "max        50.000000\n",
       "Name: results, dtype: float64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[50]['results'].apply(len).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dca0eb",
   "metadata": {},
   "source": [
    "* **count**: 1000.000000 — There are 1000 queries in the DataFrame.\n",
    "\n",
    "* **mean**: 49.961000 — On average, each query returned about 49.96 results.\n",
    "\n",
    "* **std**: 1.2332888 — The standard deviation is about 1.2, indicating little variation in the number of results per query, though slightly more than for k=20 and k=30.\n",
    "\n",
    "* **min**: 11, **25%**: 50, **50%**: 50, **75%**: 50, **max**: 50 — The minimum number of results was 11, while 25%, 50%, and 75% of the queries returned 50 results, with a maximum of 50. This means most queries returned the full 50 results, but some had fewer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4ad61c",
   "metadata": {},
   "source": [
    "We observe that as the value of k increases, the variation in the answers also increases. Although the variations are small, they are clearly reflected in the std and are also evident in the other metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3e3bd0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Statistic     Value\n",
      "0                Mean  2.795202\n",
      "1              Median  2.599902\n",
      "2  Standard Deviation  0.939617\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "all_scores = [result[3] for row in dfs[20]['results'] for result in row]\n",
    "\n",
    "mean_score = np.mean(all_scores)\n",
    "median_score = np.median(all_scores)\n",
    "std_score = np.std(all_scores)\n",
    "\n",
    "stats_df = pd.DataFrame({\n",
    "    \"Statistic\": [\"Mean\", \"Median\", \"Standard Deviation\"],\n",
    "    \"Value\": [mean_score, median_score, std_score]\n",
    "})\n",
    "\n",
    "print(stats_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7b97a8",
   "metadata": {},
   "source": [
    "* **Average score**: approximately 2.79  \n",
    "* **Median score**: approximately 2.59  \n",
    "* **Std of score**: approximately 0.94 (indicates that there is some small variability in the scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "84e1d105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Statistic     Value\n",
      "0                Mean  2.625898\n",
      "1              Median  2.439002\n",
      "2  Standard Deviation  0.891223\n"
     ]
    }
   ],
   "source": [
    "all_scores = [result[3] for row in dfs[30]['results'] for result in row]\n",
    "\n",
    "mean_score = np.mean(all_scores)\n",
    "median_score = np.median(all_scores)\n",
    "std_score = np.std(all_scores)\n",
    "\n",
    "stats_df = pd.DataFrame({\n",
    "    \"Statistic\": [\"Mean\", \"Median\", \"Standard Deviation\"],\n",
    "    \"Value\": [mean_score, median_score, std_score]\n",
    "})\n",
    "\n",
    "print(stats_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f268d7f9",
   "metadata": {},
   "source": [
    "* **Average score:** approximately 2.62\n",
    "\n",
    "* **Median score:** approximately 2.44\n",
    "\n",
    "* **Std of score:** approximately 0.89 (there is small variability in the scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e2dc8450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Statistic     Value\n",
      "0                Mean  2.412677\n",
      "1              Median  2.237310\n",
      "2  Standard Deviation  0.831417\n"
     ]
    }
   ],
   "source": [
    "all_scores = [result[3] for row in dfs[50]['results'] for result in row]\n",
    "\n",
    "mean_score = np.mean(all_scores)\n",
    "median_score = np.median(all_scores)\n",
    "std_score = np.std(all_scores)\n",
    "\n",
    "stats_df = pd.DataFrame({\n",
    "    \"Statistic\": [\"Mean\", \"Median\", \"Standard Deviation\"],\n",
    "    \"Value\": [mean_score, median_score, std_score]\n",
    "})\n",
    "\n",
    "print(stats_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccae70e0",
   "metadata": {},
   "source": [
    "* **Average score:** approximately 2.41\n",
    "\n",
    "* **Median score:** approximately 2.24\n",
    "\n",
    "* **Std of score:** approximately 0.83 (there is relatively small variability in the scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e046b254",
   "metadata": {},
   "source": [
    "## 4. Evaluation of Results  \n",
    "At this point, we will evaluate our answers by comparing them with the correct answers using the evaluation tool `trec_eval`. `trec_eval` is a standard tool used by the `TREC (Text REtrieval Conference)` community for retrieval evaluation.\n",
    "\n",
    "We will examine the evaluation metrics:  \n",
    "* **MAP (mean average precision)** and  \n",
    "* **avgPre@k (average precision at the top k retrieved documents)** for k = 5, 10, 15, 20."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633eccbc",
   "metadata": {},
   "source": [
    "We have the following files:\n",
    "\n",
    "* **queries.jsonl**: the file with the queries.\n",
    "\n",
    "* **corpus.jsonl**: the file with the correct answers.\n",
    "\n",
    "* **test.tsv**: contains the mapping of queries to correct answers.\n",
    "\n",
    "To use `trec_eval`, we will need the following files:\n",
    "\n",
    "* A -> **Qrel File**: The correct answers in a .qrel file.\n",
    "\n",
    "* B -> **Results File**: File with our results (all or for various k).\n",
    "\n",
    "Specifically, A, to be recognized by `trec_eval`, must be in the format:\n",
    "\n",
    "| query_id   | iteration  | docno      | relevance    |\n",
    "|------------|------------|------------|--------------|  \n",
    "\n",
    "Where:  \n",
    "* **query_id:** the id of the query.  \n",
    "* **iteration:** we can simply set 0 for all; it has no role.  \n",
    "* **docno:** the id of the corresponding corpus document.  \n",
    "* **relevance:** the score found in the test.tsv of the qrels.  \n",
    "\n",
    "Now, B, to be recognized by `trec_eval`, must be in the format:\n",
    "\n",
    "| query_id   | iteration  | docno      | rank    | sim    | run_id    |\n",
    "|------------|------------|------------|---------|--------|-----------|\n",
    "\n",
    "Where:  \n",
    "* **query_id:** the id of the query.  \n",
    "* **iteration:** we can simply set 0 for all; it has no role.  \n",
    "* **docno:** the id of the corresponding corpus document.  \n",
    "* **rank:** the position of the answer, i.e., if k=5, the answers will be ranked from 1 to 5 numerically, without any priority.  \n",
    "* **sim:** the score of the answer.  \n",
    "* **run_id:** any single-word string as a label, can be common for all.\n",
    "\n",
    "Creation of A:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3006028b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qrels saved\n"
     ]
    }
   ],
   "source": [
    "output_path_trec = r\"C://Users//user//Downloads//trec_eval//qrels.qrel\"\n",
    "output_path_local = \"qrels.qrel\"  \n",
    "\n",
    "df = pd.read_csv(\"./scidocs/qrels/test.tsv\", sep=\"\\t\", header=None, names=[\"query_id\", \"docno\", \"relevance\"], skiprows=1)\n",
    "df['iteration'] = 0\n",
    "df = df[['query_id', 'iteration', 'docno', 'relevance']]\n",
    "\n",
    "df.to_csv(output_path_trec, sep=' ', index=False, header=False)\n",
    "df.to_csv(output_path_local, sep=' ', index=False, header=False)\n",
    "\n",
    "print(\"Qrels saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d780152",
   "metadata": {},
   "source": [
    "Creation of Β:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "62fca8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created:\n",
      "- C://Users//user//Downloads//trec_eval\\results.txt\n",
      "- results.txt\n"
     ]
    }
   ],
   "source": [
    "trec_dir = r\"C://Users//user//Downloads//trec_eval\"\n",
    "filename = \"results.txt\"\n",
    "full_path_trec = f\"{trec_dir}\\\\{filename}\"\n",
    "full_path_local = filename\n",
    "\n",
    "with open(full_path_trec, \"w\") as f_trec, open(full_path_local, \"w\") as f_local:\n",
    "    for _, row in dfs_all.iterrows():\n",
    "        query_id = row[\"query_id\"]\n",
    "        results = row[\"results\"]\n",
    "\n",
    "        for rank, (docno, title, text, score) in enumerate(results, start=1):\n",
    "            line = f\"{query_id} 0 {docno} {rank} {score:.4f} results_all\\n\"\n",
    "            f_trec.write(line)\n",
    "            f_local.write(line)\n",
    "\n",
    "print(f\"Created:\\n- {full_path_trec}\\n- {full_path_local}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5f47faef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created:\n",
      "- C://Users//user//Downloads//trec_eval\\results_5.txt\n",
      "- results_5.txt\n",
      "Created:\n",
      "- C://Users//user//Downloads//trec_eval\\results_10.txt\n",
      "- results_10.txt\n",
      "Created:\n",
      "- C://Users//user//Downloads//trec_eval\\results_15.txt\n",
      "- results_15.txt\n",
      "Created:\n",
      "- C://Users//user//Downloads//trec_eval\\results_20.txt\n",
      "- results_20.txt\n"
     ]
    }
   ],
   "source": [
    "trec_dir = r\"C://Users//user//Downloads//trec_eval\"\n",
    "\n",
    "for k in dfs:\n",
    "    if(k<30):\n",
    "        df = dfs[k]\n",
    "        filename = f\"results_{k}.txt\"\n",
    "        full_path_trec = f\"{trec_dir}\\\\{filename}\"\n",
    "        full_path_local = filename\n",
    "\n",
    "        with open(full_path_trec, \"w\") as f_trec, open(full_path_local, \"w\") as f_local:\n",
    "            for _, row in df.iterrows():\n",
    "                query_id = row[\"query_id\"]\n",
    "                results = row[\"results\"]\n",
    "\n",
    "                for rank, (docno, title, text, score) in enumerate(results, start=1):\n",
    "                    line = f\"{query_id} 0 {docno} {rank} {score:.4f} results_{k}\\n\"\n",
    "                    f_trec.write(line)\n",
    "                    f_local.write(line)\n",
    "\n",
    "        print(f\"Created:\\n- {full_path_trec}\\n- {full_path_local}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8481bbb",
   "metadata": {},
   "source": [
    "* Now that we have created the txt files, we will execute the corresponding commands in the cmd.  \n",
    "* Below is the excerpt of the commands I ran in the cmd as a copy-paste:\n",
    "\n",
    "\n",
    "```bash\n",
    "C:\\Users\\user>cd C:\\Users\\user\\Downloads\\trec_eval\n",
    "\n",
    "C:\\Users\\user\\Downloads\\trec_eval>trec_eval -m map qrels.qrel results.txt\n",
    "      1 [main] trec_eval 10636 find_fast_cwd: WARNING: Couldn't compute FAST_CWD pointer.  Please report this problem to\n",
    "the public mailing list cygwin@cygwin.com\n",
    "map                     all     0.0949\n",
    "\n",
    "C:\\Users\\user\\Downloads\\trec_eval>trec_eval -m map_cut.5 qrels.qrel results_5.txt\n",
    "      1 [main] trec_eval 9176 find_fast_cwd: WARNING: Couldn't compute FAST_CWD pointer.  Please report this problem to\n",
    "the public mailing list cygwin@cygwin.com\n",
    "map_cut_5               all     0.0662\n",
    "\n",
    "C:\\Users\\user\\Downloads\\trec_eval>trec_eval -m map_cut.10 qrels.qrel results_10.txt\n",
    "      1 [main] trec_eval 7444 find_fast_cwd: WARNING: Couldn't compute FAST_CWD pointer.  Please report this problem to\n",
    "the public mailing list cygwin@cygwin.com\n",
    "map_cut_10              all     0.0770\n",
    "\n",
    "C:\\Users\\user\\Downloads\\trec_eval>trec_eval -m map_cut.15 qrels.qrel results_15.txt\n",
    "      1 [main] trec_eval 11012 find_fast_cwd: WARNING: Couldn't compute FAST_CWD pointer.  Please report this problem to\n",
    "the public mailing list cygwin@cygwin.com\n",
    "map_cut_15              all     0.0822\n",
    "\n",
    "C:\\Users\\user\\Downloads\\trec_eval>trec_eval -m map_cut.20 qrels.qrel results_20.txt\n",
    "      1 [main] trec_eval 6036 find_fast_cwd: WARNING: Couldn't compute FAST_CWD pointer.  Please report this problem to\n",
    "the public mailing list cygwin@cygwin.com\n",
    "map_cut_20              all     0.0847"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2a2bdc",
   "metadata": {},
   "source": [
    "### Evaluation Results with trec_eval\n",
    "\n",
    "| Evaluation Metric       | Results   | Value  |\n",
    "|-------------------------|-----------|--------|\n",
    "| MAP (Mean Avg Precision) | All       | 0.0949 |\n",
    "| avgPre@5 (map_cut.5)     | k = 5    | 0.0662 |\n",
    "| avgPre@10 (map_cut.10)   | k = 10   | 0.0770 |\n",
    "| avgPre@15 (map_cut.15)   | k = 15   | 0.0822 |\n",
    "| avgPre@20 (map_cut.20)   | k = 20   | 0.0847 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364ea992",
   "metadata": {},
   "source": [
    "## 5. Analysis of Evaluation Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c80af26",
   "metadata": {},
   "source": [
    "* The evaluation results show that, while the overall MAP is 0.0949, the avgPre@k values gradually increase from 0.0662 for k=5 to 0.0847 for k=20.  \n",
    "* This suggests that the retrieval system is indeed capable of identifying relevant documents, but many of them are not ranked at the top positions.  \n",
    "* The relatively low precision for small values of k indicates that the most relevant documents often appear further down the list.  \n",
    "* Although increasing k improves the mean precision, the rate of improvement decreases, showing diminishing returns.  \n",
    "* **Therefore, the larger our k, the easier it is to find the appropriate documents that match our queries.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61417984",
   "metadata": {},
   "source": [
    "# Information Retrieval Systems Assignment - Phase 2  \n",
    "\n",
    "* In the second phase, we will expand the queries of the `IR2025` collection with synonymous terms that we will extract from `WordNet`.  \n",
    "* Let's take a closer look at what it provides:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a44dde2",
   "metadata": {},
   "source": [
    "### Semantic Relations of WordNet\n",
    "\n",
    "WordNet is a lexical database (in English) that organizes words into **synonym sets (synsets)** and maps various semantic relations between them. The main types of relations that WordNet can identify, using the word **\"car\"** as an example where applicable, are:\n",
    "\n",
    "| Relation      | Description                        | Example with \"car\"                     |\n",
    "|---------------|------------------------------------|----------------------------------------|\n",
    "| Synonym       | Same/similar meaning               | Car ↔ Auto, Motorcar                   |\n",
    "| Hypernym      | More general term                  | Vehicle ← Car                          |\n",
    "| Hyponym       | More specific term                 | Car → Sedan, SUV                       |\n",
    "| Meronym       | Part of the whole                  | Car → Engine, Wheel                     |\n",
    "| Holonym       | Whole containing the part          | Fleet ← Car                             |\n",
    "| Entailment    | Logical consequence of action      | Buy → Pay                               |\n",
    "| Troponym      | Specific manner of action          | Drive → Skid, Race                      |\n",
    "| Antonym       | Opposite meaning                   | Buy ↔ Sell                              |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fe6396",
   "metadata": {},
   "source": [
    "## 1. Defining Tools for Finding Synonyms\n",
    "* We will use the `NLTK` library, which we have already imported in previous steps.\n",
    "* We will create appropriate methods to further expand our queries using various synonyms from `WordNet`.\n",
    "* Let's download `WordNet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e15ba53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acff993d",
   "metadata": {},
   "source": [
    "* We'll choose WordNet synonyms for only certain parts of speech. We will check **not to include common words**, i.e., stopwords, and **we will focus on nouns**.  \n",
    "* We will use the stopwords provided by NLTK as a criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "551e1a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def get_noun_synonyms(word, max_synonyms=4):\n",
    "    synonyms = set()\n",
    "    if word.lower() in stop_words:\n",
    "        return []\n",
    "    for synset in wn.synsets(word, pos=wn.NOUN):  # only noun synsets\n",
    "        for lemma in synset.lemmas():\n",
    "            name = lemma.name().replace('_', ' ')\n",
    "            if name.lower() not in stop_words:\n",
    "                synonyms.add(name)\n",
    "                if len(synonyms) >= max_synonyms:\n",
    "                    break\n",
    "        if len(synonyms) >= max_synonyms:\n",
    "            break\n",
    "    return list(synonyms)\n",
    "\n",
    "def get_noun_hypernyms(word, max_hypernyms=4):\n",
    "    hypernyms = set()\n",
    "    if word.lower() in stop_words:\n",
    "        return hypernyms\n",
    "    for syn in wn.synsets(word, pos=wn.NOUN):\n",
    "        for hypernym in syn.hypernyms():\n",
    "            for lemma in hypernym.lemmas():\n",
    "                name = lemma.name().replace('_', ' ')\n",
    "                if name.lower() not in stop_words:\n",
    "                    hypernyms.add(name)\n",
    "                    if len(hypernyms) >= max_hypernyms:\n",
    "                        break\n",
    "            if len(hypernyms) >= max_hypernyms:\n",
    "                break\n",
    "        if len(hypernyms) >= max_hypernyms:\n",
    "                break    \n",
    "    return hypernyms\n",
    "\n",
    "def get_noun_hyponyms(word, max_hyponyms=4):\n",
    "    hyponyms = set()\n",
    "    if word.lower() in stop_words:\n",
    "        return hyponyms\n",
    "    for syn in wn.synsets(word, pos=wn.NOUN):\n",
    "        for hyponym in syn.hyponyms():\n",
    "            for lemma in hyponym.lemmas():\n",
    "                name = lemma.name().replace('_', ' ')\n",
    "                if name.lower() not in stop_words:\n",
    "                    hyponyms.add(name)\n",
    "                    if len(hyponyms) >= max_hyponyms:\n",
    "                        break\n",
    "            if len(hyponyms) >= max_hyponyms:\n",
    "                break\n",
    "        if len(hyponyms) >= max_hyponyms:\n",
    "            break\n",
    "    return hyponyms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b4712e",
   "metadata": {},
   "source": [
    "* Let's ckeck that our functions work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2568c31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sir Herbert Beerbohm Tree', 'tree diagram', 'tree', 'Tree']\n"
     ]
    }
   ],
   "source": [
    "print(get_noun_synonyms('tree', 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0791e878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'edible fruit', 'false fruit', 'apple tree', 'pome'}\n"
     ]
    }
   ],
   "source": [
    "print(get_noun_hypernyms(\"apple\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "395b7661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'client', 'number cruncher', 'guest', 'node'}\n"
     ]
    }
   ],
   "source": [
    "print(get_noun_hyponyms('computer'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69d482b",
   "metadata": {},
   "source": [
    "* Our functions seem to work as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456ca6ed",
   "metadata": {},
   "source": [
    "## 2. Expanding IR2025 Queries with Synonymous Terms from WordNet\n",
    "For completeness, we will expand the queries in two separate ways:\n",
    "* 1st Method: Expansion by adding **Synonymous Terms**\n",
    "* 2nd Method: Using **Hypernyms** and **Hyponyms**\n",
    "\n",
    "We will use the `queries` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3175f3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "queries_synonyms = []\n",
    "for q in queries:\n",
    "    query_text = q.get(\"text\", \"\")\n",
    "    id = q.get(\"_id\", \"\")\n",
    "    words = word_tokenize(query_text)\n",
    "    new_query = set()\n",
    "    for word in words:\n",
    "        synonyms = get_noun_synonyms(word)\n",
    "        new_query.update(synonyms)  \n",
    "    query_str = ' '.join(new_query)  \n",
    "    queries_synonyms.append((id,query_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "726fb38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 before adding synonyms:\n",
      "{'_id': '78495383450e02c5fe817e408726134b3084905d', 'text': 'A Direct Search Method to solve Economic Dispatch Problem with Valve-Point Effect', 'metadata': {'authors': ['50306438', '15303316', '1976596'], 'year': 2014, 'cited_by': ['38e78343cfd5c013decf49e8cf008ddf6458200f'], 'references': ['632589828c8b9fca2c3a59e97451fde8fa7d188d', '4cf296b9d4ef79b838dc565e6e84ab9b089613de', '86e87db2dab958f1bd5877dc7d5b8105d6e31e46', '4b031fa8bf63e17e2100cf31ba6e11d8f80ff2a8', 'a718c6ca7a1db49bb2328d43f775783e8ec6f985', 'cf51cfb5b221500b882efee60b794bc11635267e', '6329874126a4e753f98c40eaa74b666d0f14eaba', 'a27b6025d147febb54761345eafdd73954467aca']}}\n",
      "\n",
      "Query 1 after adding synonyms:\n",
      "('78495383450e02c5fe817e408726134b3084905d', 'trouble search despatch dispatch lookup hunt hunting job consequence outcome method method acting effect result problem communique shipment')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Query 1 before adding synonyms:\\n{queries[0]}\\n\")\n",
    "print(f\"Query 1 after adding synonyms:\\n{queries_synonyms[0]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff8a99f",
   "metadata": {},
   "source": [
    "* We see that the query has been expanded according to the first method (expansion with synonyms).  \n",
    "* We also see that the stopword A is ignored, meaning no synonym is found for it.  \n",
    "* Let's follow the same logic for implementing the 2nd method (expansion with hypernyms and hyponyms)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8277bdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_hyper_hypo = []\n",
    "for q in queries:\n",
    "    query_text = q.get(\"text\", \"\")\n",
    "    id = q.get(\"_id\", \"\")\n",
    "    words = word_tokenize(query_text)\n",
    "    new_query = set()\n",
    "    for word in words:\n",
    "        #getting hypernyms:\n",
    "        hypernyms = get_noun_hypernyms(word)\n",
    "        hypernyms.add(word) \n",
    "        new_query.update(hypernyms) \n",
    "        #getting hypernyms:\n",
    "        hyponyms = get_noun_hyponyms(word)\n",
    "        hyponyms.add(word) \n",
    "        new_query.update(hyponyms) \n",
    "    query_str = ' '.join(new_query)  \n",
    "    queries_hyper_hypo.append((id,query_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "06d957d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 78495383450e02c5fe817e408726134b3084905d before adding hypernyms and hyponyms:\n",
      "A Direct Search Method to solve Economic Dispatch Problem with Valve-Point Effect\n",
      "\n",
      "Query 78495383450e02c5fe817e408726134b3084905d after adding hypernyms and hyponyms:\n",
      "acting playing investigating exploration question impression to difficulty looking solution activity phenomenon balance-of-payments problem Dispatch Economic report Method shakedown riddle news report solve bandwagon effect technique system of rules with account change appearance system manhunt pons asinorum playacting A Problem visual aspect impact Search operation wallop Valve-Point story investigation Direct head know-how race problem Effect reshipment\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Query {queries[0].get(\"_id\", \"\")} before adding hypernyms and hyponyms:\\n{queries[0].get(\"text\", \"\")}\\n\")\n",
    "print(f\"Query {queries_hyper_hypo[0][0]} after adding hypernyms and hyponyms:\\n{queries_hyper_hypo[0][1]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e5cd84",
   "metadata": {},
   "source": [
    "## 3. Executing Queries  \n",
    "In this step, we will run queries on the index and collect the machine's responses. We will use the queries that were already available in the `scidocs` folder, which we also used for building the indexes. We will keep the top k retrieved documents, for `k = 20, 30, 50`.  \n",
    "* We will use the `search_document` function from Phase 1, which performs a single query. \n",
    "* We will first implement the queries that have been expanded with their synonyms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "38920ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No results found for query ID 0c8a029180e8ee5a7a8c886738576b12d3f6530d.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "for query_id, query_text in queries_synonyms:\n",
    "    if not query_text:\n",
    "        continue\n",
    "\n",
    "    response = search_document(query_text, size=1000)\n",
    "    hits = response['hits']['hits']\n",
    "\n",
    "    if not hits:\n",
    "        print(f\"No results found for query ID {query_id}.\\n\")\n",
    "        continue\n",
    "\n",
    "    results_list = []\n",
    "    for hit in hits:\n",
    "        id = hit['_id']\n",
    "        source = hit['_source']\n",
    "        score = hit['_score']\n",
    "        title = source.get('title', 'N/A')\n",
    "        text = source.get('text', 'N/A')\n",
    "        results_list.append((id, title, text, score))\n",
    "\n",
    "    data.append({\n",
    "        \"query_id\": query_id,\n",
    "        \"query\": query_text,\n",
    "        \"results\": results_list\n",
    "    })\n",
    "\n",
    "dfs_all_synonyms = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b674d5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No results found for query ID 0c8a029180e8ee5a7a8c886738576b12d3f6530d.\n",
      "\n",
      "No results found for query ID 0c8a029180e8ee5a7a8c886738576b12d3f6530d.\n",
      "\n",
      "No results found for query ID 0c8a029180e8ee5a7a8c886738576b12d3f6530d.\n",
      "\n",
      "No results found for query ID 0c8a029180e8ee5a7a8c886738576b12d3f6530d.\n",
      "\n",
      "No results found for query ID 0c8a029180e8ee5a7a8c886738576b12d3f6530d.\n",
      "\n",
      "No results found for query ID 0c8a029180e8ee5a7a8c886738576b12d3f6530d.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k_values = [5, 10, 15, 20, 30, 50]\n",
    "dfs_synonyms = {}\n",
    "\n",
    "for k in k_values:\n",
    "    data = []\n",
    "    \n",
    "    for query_id, query_text in queries_synonyms:\n",
    "        if not query_text:\n",
    "            continue\n",
    "        \n",
    "        response = search_document(query_text, size=k)\n",
    "        hits = response['hits']['hits']\n",
    "        \n",
    "        if not hits:\n",
    "            print(f\"No results found for query ID {query_id}.\\n\")\n",
    "            continue\n",
    "        \n",
    "        results_list = []\n",
    "        for hit in hits:\n",
    "            id = hit['_id']\n",
    "            source = hit['_source']\n",
    "            score = hit['_score']\n",
    "            title = source.get('title', 'N/A')\n",
    "            text = source.get('text', 'N/A')\n",
    "            results_list.append((id, title, text, score))\n",
    "        \n",
    "        data.append({\n",
    "            \"query_id\": query_id,\n",
    "            \"query\": query_text,\n",
    "            \"results\": results_list\n",
    "        })\n",
    "    \n",
    "    dfs_synonyms[k] = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa0a0da",
   "metadata": {},
   "source": [
    "* We see that there were **answers for most of our queries** (the IDs of the **few** cases where there were no answers are printed).  \n",
    "* `dfs_synonyms` is a dictionary where each key is one of the k values (5, 10, 15, 20, 30, 50) and each value is a pandas DataFrame (as in Part 3 of Phase 1).  \n",
    "* Let's examine the contents of this dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "166eaffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(998, 3)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_synonyms[20].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7b6a6590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(998, 3)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_synonyms[30].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "18aaa9e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(998, 3)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_synonyms[50].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3c63e5d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    998.000000\n",
       "mean      19.994990\n",
       "std        0.158272\n",
       "min       15.000000\n",
       "25%       20.000000\n",
       "50%       20.000000\n",
       "75%       20.000000\n",
       "max       20.000000\n",
       "Name: results, dtype: float64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_synonyms[20]['results'].apply(len).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62613e7b",
   "metadata": {},
   "source": [
    "* **count:** 998.0 → There are 1000 queries in the DataFrame, 998 were answered with our updated queries.\n",
    "\n",
    "* **mean:** 19.994990 → On average, each query returned 19.9 results.\n",
    "\n",
    "* **std:** 0.158272 → The standard deviation is almost 0.16, indicating small deviation.\n",
    "\n",
    "* **min:** 15, **20, 25%, 50%, 75%, max** all equal 20 → The number of results is consistently 20 except for a few queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b763f1d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    998.000000\n",
       "mean      29.984970\n",
       "std        0.474817\n",
       "min       15.000000\n",
       "25%       30.000000\n",
       "50%       30.000000\n",
       "75%       30.000000\n",
       "max       30.000000\n",
       "Name: results, dtype: float64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_synonyms[30]['results'].apply(len).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9696fa41",
   "metadata": {},
   "source": [
    "* **count:** 998.0 → There are 1000 queries in the DataFrame, 998 were answered with our updated queries.\n",
    "\n",
    "* **mean:** 29.984970 → On average, each query returned almost 30 results.\n",
    "\n",
    "* **std:** 0.474817 → The standard deviation is almost 0.48, indicating small deviation.\n",
    "\n",
    "* **min:** 15, **20, 25%, 50%, 75%, max** all equal 30 → The number of results is consistently 30 except for a few queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6d4ed5e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    998.000000\n",
       "mean      49.964930\n",
       "std        1.107906\n",
       "min       15.000000\n",
       "25%       50.000000\n",
       "50%       50.000000\n",
       "75%       50.000000\n",
       "max       50.000000\n",
       "Name: results, dtype: float64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_synonyms[50]['results'].apply(len).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c42d426",
   "metadata": {},
   "source": [
    "* **count:** 998.0 → There are 1000 queries in the DataFrame, 998 were answered with our updated queries.\n",
    "\n",
    "* **mean:** 49.964930 → On average, each query returned almost 50 results.\n",
    "\n",
    "* **std:** 1.107906 → The standard deviation is almost 1, indicating small deviation, larger than for the previous k values.\n",
    "\n",
    "* **min:** 15, **20, 25%, 50%, 75%, max** all equal 50 → The number of results is consistently 50 except for a few queries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643fc2cd",
   "metadata": {},
   "source": [
    "* We observe that as the value of k increases, the variation in the answers also increases.  \n",
    "* **We notice that, in this case, with the query expansion, we retrieve fewer documents.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a3cb8758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Statistic     Value\n",
      "0                Mean  4.110391\n",
      "1              Median  3.937426\n",
      "2  Standard Deviation  1.535066\n"
     ]
    }
   ],
   "source": [
    "all_scores = [result[3] for row in dfs_synonyms[20]['results'] for result in row]\n",
    "\n",
    "mean_score = np.mean(all_scores)\n",
    "median_score = np.median(all_scores)\n",
    "std_score = np.std(all_scores)\n",
    "\n",
    "stats_df = pd.DataFrame({\n",
    "    \"Statistic\": [\"Mean\", \"Median\", \"Standard Deviation\"],\n",
    "    \"Value\": [mean_score, median_score, std_score]\n",
    "})\n",
    "\n",
    "print(stats_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546dd5c5",
   "metadata": {},
   "source": [
    "* **Average score:** approximately 4.1\n",
    "\n",
    "* **Median score:** approximately 3.9\n",
    "\n",
    "* **Std of score:** approximately 1.5 (there is variability in the scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d53f4ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Statistic     Value\n",
      "0                Mean  3.898443\n",
      "1              Median  3.727660\n",
      "2  Standard Deviation  1.462083\n"
     ]
    }
   ],
   "source": [
    "all_scores = [result[3] for row in dfs_synonyms[30]['results'] for result in row]\n",
    "\n",
    "mean_score = np.mean(all_scores)\n",
    "median_score = np.median(all_scores)\n",
    "std_score = np.std(all_scores)\n",
    "\n",
    "stats_df = pd.DataFrame({\n",
    "    \"Statistic\": [\"Mean\", \"Median\", \"Standard Deviation\"],\n",
    "    \"Value\": [mean_score, median_score, std_score]\n",
    "})\n",
    "\n",
    "print(stats_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1724aec",
   "metadata": {},
   "source": [
    "* **Average score:** approximately 3.9\n",
    "\n",
    "* **Median score:** approximately 3.7\n",
    "\n",
    "* **Std of score:** approximately 1.5 (there is variability in the scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "03adba92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Statistic     Value\n",
      "0                Mean  3.626761\n",
      "1              Median  3.474216\n",
      "2  Standard Deviation  1.372217\n"
     ]
    }
   ],
   "source": [
    "all_scores = [result[3] for row in dfs_synonyms[50]['results'] for result in row]\n",
    "\n",
    "mean_score = np.mean(all_scores)\n",
    "median_score = np.median(all_scores)\n",
    "std_score = np.std(all_scores)\n",
    "\n",
    "stats_df = pd.DataFrame({\n",
    "    \"Statistic\": [\"Mean\", \"Median\", \"Standard Deviation\"],\n",
    "    \"Value\": [mean_score, median_score, std_score]\n",
    "})\n",
    "\n",
    "print(stats_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d74efca",
   "metadata": {},
   "source": [
    "* **Average score:** approximately 3.6\n",
    "\n",
    "* **Median score:** approximately 3.5\n",
    "\n",
    "* **Std of score:** approximately 1.4 (there is variability in the scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937b2118",
   "metadata": {},
   "source": [
    "* Now we will implement the queries that have been expanded with their hypernyms and hyponyms.  \n",
    "* We will also keep the cases k=5, 10, 15 because they will be useful in Part 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "96d552a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for query_id, query_text in queries_hyper_hypo:\n",
    "    if not query_text:\n",
    "        continue\n",
    "    \n",
    "    response = search_document(query_text, size=1000)  \n",
    "    hits = response['hits']['hits']\n",
    "    \n",
    "    if not hits:\n",
    "        print(f\"No results found for query ID {query_id}.\\n\")\n",
    "        continue\n",
    "    \n",
    "    results_list = []\n",
    "    for hit in hits:\n",
    "        id = hit['_id']\n",
    "        source = hit['_source']\n",
    "        score = hit['_score']\n",
    "        title = source.get('title', 'N/A')\n",
    "        text = source.get('text', 'N/A')\n",
    "        results_list.append((id, title, text, score))\n",
    "    \n",
    "    data.append({\n",
    "        \"query_id\": query_id,\n",
    "        \"query\": query_text,\n",
    "        \"results\": results_list\n",
    "    })\n",
    "\n",
    "dfs_all_hyper_hypo = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "79056ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = [5, 10, 15, 20, 30, 50]\n",
    "dfs_hyper_hypo = {}\n",
    "\n",
    "for k in k_values:\n",
    "    data = []\n",
    "    \n",
    "    for query_id, query_text in queries_hyper_hypo:\n",
    "        if not query_text:\n",
    "            continue\n",
    "        \n",
    "        response = search_document(query_text, size=k)\n",
    "        hits = response['hits']['hits']\n",
    "        \n",
    "        if not hits:\n",
    "            print(\"  No results found.\\n\")\n",
    "            continue\n",
    "        \n",
    "        results_list = []\n",
    "        for hit in hits:\n",
    "            id = hit['_id']\n",
    "            source = hit['_source']\n",
    "            score = hit['_score']\n",
    "            title = source.get('title', 'N/A')\n",
    "            text = source.get('text', 'N/A')\n",
    "            results_list.append((id, title, text, score))\n",
    "        \n",
    "        data.append({\n",
    "            \"query_id\": query_id,\n",
    "            \"query\": query_text,\n",
    "            \"results\": results_list\n",
    "        })\n",
    "    \n",
    "    dfs_hyper_hypo[k] = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c0b9e551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1000.0\n",
       "mean       20.0\n",
       "std         0.0\n",
       "min        20.0\n",
       "25%        20.0\n",
       "50%        20.0\n",
       "75%        20.0\n",
       "max        20.0\n",
       "Name: results, dtype: float64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_hyper_hypo[20]['results'].apply(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1a9424ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1000.0\n",
       "mean       30.0\n",
       "std         0.0\n",
       "min        30.0\n",
       "25%        30.0\n",
       "50%        30.0\n",
       "75%        30.0\n",
       "max        30.0\n",
       "Name: results, dtype: float64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_hyper_hypo[30]['results'].apply(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "afcabdb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1000.0\n",
       "mean       50.0\n",
       "std         0.0\n",
       "min        50.0\n",
       "25%        50.0\n",
       "50%        50.0\n",
       "75%        50.0\n",
       "max        50.0\n",
       "Name: results, dtype: float64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_hyper_hypo[50]['results'].apply(len).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40eddc5",
   "metadata": {},
   "source": [
    "* The results appear to be complete and show consistent behavior.  \n",
    "* The results resemble the case of Phase 1, before query expansion.  \n",
    "* **We notice that, in this case, with the query expansion, we do not retrieve fewer documents.**  \n",
    "* Let's, however, check the scores of the answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "970f904a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Statistic     Value\n",
      "0                Mean  6.294461\n",
      "1              Median  5.906011\n",
      "2  Standard Deviation  2.328033\n"
     ]
    }
   ],
   "source": [
    "all_scores = [result[3] for row in dfs_hyper_hypo[20]['results'] for result in row]\n",
    "\n",
    "mean_score = np.mean(all_scores)\n",
    "median_score = np.median(all_scores)\n",
    "std_score = np.std(all_scores)\n",
    "\n",
    "stats_df = pd.DataFrame({\n",
    "    \"Statistic\": [\"Mean\", \"Median\", \"Standard Deviation\"],\n",
    "    \"Value\": [mean_score, median_score, std_score]\n",
    "})\n",
    "\n",
    "print(stats_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e864cc1",
   "metadata": {},
   "source": [
    "* **Average score:** approximately 6.4\n",
    "\n",
    "* **Median score:** approximately 6\n",
    "\n",
    "* **Std of score:** approximately 2.3 (there is high variability in the scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "47ca58a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Statistic     Value\n",
      "0                Mean  6.002471\n",
      "1              Median  5.631777\n",
      "2  Standard Deviation  2.234365\n"
     ]
    }
   ],
   "source": [
    "all_scores = [result[3] for row in dfs_hyper_hypo[30]['results'] for result in row]\n",
    "\n",
    "mean_score = np.mean(all_scores)\n",
    "median_score = np.median(all_scores)\n",
    "std_score = np.std(all_scores)\n",
    "\n",
    "stats_df = pd.DataFrame({\n",
    "    \"Statistic\": [\"Mean\", \"Median\", \"Standard Deviation\"],\n",
    "    \"Value\": [mean_score, median_score, std_score]\n",
    "})\n",
    "\n",
    "print(stats_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a859a768",
   "metadata": {},
   "source": [
    "* **Average score:** approximately 6\n",
    "\n",
    "* **Median score:** approximately 5.7\n",
    "\n",
    "* **Std of score:** approximately 2.2 (high variability in the scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8dec1203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Statistic     Value\n",
      "0                Mean  5.625489\n",
      "1              Median  5.289726\n",
      "2  Standard Deviation  2.115904\n"
     ]
    }
   ],
   "source": [
    "all_scores = [result[3] for row in dfs_hyper_hypo[50]['results'] for result in row]\n",
    "\n",
    "mean_score = np.mean(all_scores)\n",
    "median_score = np.median(all_scores)\n",
    "std_score = np.std(all_scores)\n",
    "\n",
    "stats_df = pd.DataFrame({\n",
    "    \"Statistic\": [\"Mean\", \"Median\", \"Standard Deviation\"],\n",
    "    \"Value\": [mean_score, median_score, std_score]\n",
    "})\n",
    "\n",
    "print(stats_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e0cfc3",
   "metadata": {},
   "source": [
    "* **Average score:** approximately 5.7\n",
    "\n",
    "* **Median score:** approximately 5.4\n",
    "\n",
    "* **Std of score:** approximately 2 (high variability in the scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26f591d",
   "metadata": {},
   "source": [
    "Let's examine the performance of the relevance score comparatively for all k and for all query categories.\n",
    "\n",
    "| Case                       | k  | Mean      | Median    | Std         |\n",
    "|-----------------------------|----|-----------|-----------|-------------|\n",
    "| Simple                      | 20 | 2.795202  | 2.599902  | 0.939617    |\n",
    "| Simple                      | 30 | 2.625898  | 2.439002  | 0.891223    |\n",
    "| Simple                      | 50 | 2.412677  | 2.237310  | 0.831417    |\n",
    "| Synonyms                    | 20 | 4.110391  | 3.937426  | 1.535066    |\n",
    "| Synonyms                    | 30 | 3.898443  | 3.727660  | 1.462083    |\n",
    "| Synonyms                    | 50 | 3.626761  | 3.474216  | 1.372217    |\n",
    "| Hypernyms and Hyponyms      | 20 | 6.367802  | 6.029314  | 2.323537    |\n",
    "| Hypernyms and Hyponyms      | 30 | 6.077830  | 5.750344  | 2.239387    |\n",
    "| Hypernyms and Hyponyms      | 50 | 5.704961  | 5.394706  | 2.132761    |\n",
    "\n",
    "**Conclusions:**\n",
    "* In the simple case, as k increases, the mean and median of the relevance score gradually decrease, which is expected: the more answers collected, the more likely less relevant answers are included.  \n",
    "* The same trend is observed in the synonyms case, although the values are significantly higher, indicating that **synonyms lead to denser results of high relevance**. However, we also notice a higher standard deviation than in the simple case.  \n",
    "* In the case of hypernyms and hyponyms, **the relevance values are higher but also more unstable (higher standard deviation)**, indicating high heterogeneity in the answers; that is, results are not always highly relevant.  \n",
    "\n",
    "The synonym approach appears to achieve the **best scores**, when considered **together with a reasonable standard deviation**, unlike the hypernyms and hyponyms approach. However, we note that although it gives higher scores, this may imply artificially enhanced relevance due to words that are marginally synonymous, introducing a risk of semantic ambiguity. From this perspective, the simple case is safer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdb95d4",
   "metadata": {},
   "source": [
    "# 4. Evaluation of Results  \n",
    "At this point, we will evaluate our answers by comparing them with the correct answers using the evaluation tool `trec_eval`. `trec_eval` is a standard tool used by the `TREC (Text REtrieval Conference)` community for retrieval evaluation.\n",
    "\n",
    "We will examine the evaluation metrics:  \n",
    "* **MAP (mean average precision)** and  \n",
    "* **avgPre@k (average precision at the top k retrieved documents)** for k = 5, 10, 15, 20, for both cases of our query expansions.\n",
    "\n",
    "We will modify our data so that it is stored in a format suitable for `trec_eval`, as in Phase 1 of the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c16b5ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Synonyms Results\n",
      "Created:\n",
      "- C://Users//user//Downloads//trec_eval\\results_synonyms_5.txt\n",
      "- results_synonyms_5.txt\n",
      "Created:\n",
      "- C://Users//user//Downloads//trec_eval\\results_synonyms_10.txt\n",
      "- results_synonyms_10.txt\n",
      "Created:\n",
      "- C://Users//user//Downloads//trec_eval\\results_synonyms_15.txt\n",
      "- results_synonyms_15.txt\n",
      "Created:\n",
      "- C://Users//user//Downloads//trec_eval\\results_synonyms_20.txt\n",
      "- results_synonyms_20.txt\n",
      "Created Hypernyms/Hyponyms Results\n",
      "Created:\n",
      "- C://Users//user//Downloads//trec_eval\\results_hyper_hypo_5.txt\n",
      "- results_hyper_hypo_5.txt\n",
      "Created:\n",
      "- C://Users//user//Downloads//trec_eval\\results_hyper_hypo_10.txt\n",
      "- results_hyper_hypo_10.txt\n",
      "Created:\n",
      "- C://Users//user//Downloads//trec_eval\\results_hyper_hypo_15.txt\n",
      "- results_hyper_hypo_15.txt\n",
      "Created:\n",
      "- C://Users//user//Downloads//trec_eval\\results_hyper_hypo_20.txt\n",
      "- results_hyper_hypo_20.txt\n"
     ]
    }
   ],
   "source": [
    "trec_dir = r\"C://Users//user//Downloads//trec_eval\"\n",
    "\n",
    "filename = \"results_synonyms.txt\"\n",
    "full_path_trec = f\"{trec_dir}\\\\{filename}\"\n",
    "full_path_local = filename\n",
    "\n",
    "with open(full_path_trec, \"w\") as f_trec, open(full_path_local, \"w\") as f_local:\n",
    "    for _, row in dfs_all_synonyms.iterrows():\n",
    "        query_id = row[\"query_id\"]\n",
    "        results = row[\"results\"]\n",
    "\n",
    "        for rank, (docno, title, text, score) in enumerate(results, start=1):\n",
    "            line = f\"{query_id} 0 {docno} {rank} {score:.4f} results_synonyms\\n\"\n",
    "            f_trec.write(line)\n",
    "            f_local.write(line)\n",
    "\n",
    "print(f\"Created Synonyms Results\")\n",
    "\n",
    "for k in dfs_synonyms:\n",
    "    if(k<30):\n",
    "        df = dfs_synonyms[k]\n",
    "        filename = f\"results_synonyms_{k}.txt\"\n",
    "        full_path_trec = f\"{trec_dir}\\\\{filename}\"\n",
    "        full_path_local = filename\n",
    "\n",
    "        with open(full_path_trec, \"w\") as f_trec, open(full_path_local, \"w\") as f_local:\n",
    "            for _, row in df.iterrows():\n",
    "                query_id = row[\"query_id\"]\n",
    "                results = row[\"results\"]\n",
    "\n",
    "                for rank, (docno, title, text, score) in enumerate(results, start=1):\n",
    "                    line = f\"{query_id} 0 {docno} {rank} {score:.4f} results_synonyms_{k}\\n\"\n",
    "                    f_trec.write(line)\n",
    "                    f_local.write(line)\n",
    "\n",
    "        print(f\"Created:\\n- {full_path_trec}\\n- {full_path_local}\")\n",
    "\n",
    "filename = \"results_hyper_hypo.txt\"\n",
    "full_path_trec = f\"{trec_dir}\\\\{filename}\"\n",
    "full_path_local = filename\n",
    "\n",
    "with open(full_path_trec, \"w\") as f_trec, open(full_path_local, \"w\") as f_local:\n",
    "    for _, row in dfs_all_hyper_hypo.iterrows():\n",
    "        query_id = row[\"query_id\"]\n",
    "        results = row[\"results\"]\n",
    "\n",
    "        for rank, (docno, title, text, score) in enumerate(results, start=1):\n",
    "            line = f\"{query_id} 0 {docno} {rank} {score:.4f} results_hyper_hypo\\n\"\n",
    "            f_trec.write(line)\n",
    "            f_local.write(line)\n",
    "\n",
    "print(f\"Created Hypernyms/Hyponyms Results\")\n",
    "\n",
    "for k in dfs_hyper_hypo:\n",
    "    if(k<30):\n",
    "        df = dfs_hyper_hypo[k]\n",
    "        filename = f\"results_hyper_hypo_{k}.txt\"\n",
    "        full_path_trec = f\"{trec_dir}\\\\{filename}\"\n",
    "        full_path_local = filename\n",
    "\n",
    "        with open(full_path_trec, \"w\") as f_trec, open(full_path_local, \"w\") as f_local:\n",
    "            for _, row in df.iterrows():\n",
    "                query_id = row[\"query_id\"]\n",
    "                results = row[\"results\"]\n",
    "\n",
    "                for rank, (docno, title, text, score) in enumerate(results, start=1):\n",
    "                    line = f\"{query_id} 0 {docno} {rank} {score:.4f} results_hyper_hypo_{k}\\n\"\n",
    "                    f_trec.write(line)\n",
    "                    f_local.write(line)\n",
    "\n",
    "        print(f\"Created:\\n- {full_path_trec}\\n- {full_path_local}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0315aca1",
   "metadata": {},
   "source": [
    "* Now that we have created the txt files, we will execute the corresponding commands in the cmd.  \n",
    "* We will first examine the case of queries expanded with synonyms.  \n",
    "* Below is the excerpt of the commands I ran in the cmd as a copy-paste:\n",
    "\n",
    "\n",
    "```bash\n",
    "C:\\Users\\user\\Downloads\\trec_eval>trec_eval -m map qrels.qrel results_synonyms.txt\n",
    "      1 [main] trec_eval 8136 find_fast_cwd: WARNING: Couldn't compute FAST_CWD pointer.  Please report this problem to\n",
    "the public mailing list cygwin@cygwin.com\n",
    "map                     all     0.0454\n",
    "\n",
    "C:\\Users\\user\\Downloads\\trec_eval>trec_eval -m map_cut.5 qrels.qrel results_synonyms_5.txt\n",
    "      1 [main] trec_eval 1680 find_fast_cwd: WARNING: Couldn't compute FAST_CWD pointer.  Please report this problem to\n",
    "the public mailing list cygwin@cygwin.com\n",
    "map_cut_5               all     0.0304\n",
    "\n",
    "C:\\Users\\user\\Downloads\\trec_eval>trec_eval -m map_cut.10 qrels.qrel results_synonyms_10.txt\n",
    "      1 [main] trec_eval 11916 find_fast_cwd: WARNING: Couldn't compute FAST_CWD pointer.  Please report this problem to\n",
    "the public mailing list cygwin@cygwin.com\n",
    "map_cut_10              all     0.0352\n",
    "\n",
    "C:\\Users\\user\\Downloads\\trec_eval>trec_eval -m map_cut.15 qrels.qrel results_synonyms_15.txt\n",
    "      1 [main] trec_eval 9584 find_fast_cwd: WARNING: Couldn't compute FAST_CWD pointer.  Please report this problem to\n",
    "the public mailing list cygwin@cygwin.com\n",
    "map_cut_15              all     0.0371\n",
    "\n",
    "C:\\Users\\user\\Downloads\\trec_eval>trec_eval -m map_cut.20 qrels.qrel results_synonyms_20.txt\n",
    "      1 [main] trec_eval 10804 find_fast_cwd: WARNING: Couldn't compute FAST_CWD pointer.  Please report this problem to\n",
    "the public mailing list cygwin@cygwin.com\n",
    "map_cut_20              all     0.0384"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a18360",
   "metadata": {},
   "source": [
    "In summary, our results:\n",
    "\n",
    "| Evaluation Metric       | Results   | Value  |\n",
    "|-------------------------|-----------|--------|\n",
    "| MAP (Mean Avg Precision) | All       | 0.0454 |\n",
    "| avgPre@5 (map_cut.5)     | k = 5    | 0.0304 |\n",
    "| avgPre@10 (map_cut.10)   | k = 10   | 0.0352 |\n",
    "| avgPre@15 (map_cut.15)   | k = 15   | 0.0371 |\n",
    "| avgPre@20 (map_cut.20)   | k = 20   | 0.0384 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf3ada8",
   "metadata": {},
   "source": [
    "* Now we will examine the case of queries expanded with hypernyms and hyponyms.  \n",
    "* Below is the excerpt of the commands I ran in the cmd as a copy-paste:\n",
    "\n",
    "\n",
    "```bash\n",
    "C:\\Users\\user\\Downloads\\trec_eval>trec_eval -m map qrels.qrel results_hyper_hypo.txt\n",
    "      1 [main] trec_eval 6588 find_fast_cwd: WARNING: Couldn't compute FAST_CWD pointer.  Please report this problem to\n",
    "the public mailing list cygwin@cygwin.com\n",
    "map                     all     0.0433\n",
    "\n",
    "C:\\Users\\user\\Downloads\\trec_eval>trec_eval -m map_cut.5 qrels.qrel results_hyper_hypo_5.txt\n",
    "      1 [main] trec_eval 2084 find_fast_cwd: WARNING: Couldn't compute FAST_CWD pointer.  Please report this problem to\n",
    "the public mailing list cygwin@cygwin.com\n",
    "map_cut_5               all     0.0278\n",
    "\n",
    "C:\\Users\\user\\Downloads\\trec_eval>trec_eval -m map_cut.10 qrels.qrel results_hyper_hypo_10.txt\n",
    "      1 [main] trec_eval 14060 find_fast_cwd: WARNING: Couldn't compute FAST_CWD pointer.  Please report this problem to\n",
    "the public mailing list cygwin@cygwin.com\n",
    "map_cut_10              all     0.0320\n",
    "\n",
    "C:\\Users\\user\\Downloads\\trec_eval>trec_eval -m map_cut.15 qrels.qrel results_hyper_hypo_15.txt\n",
    "      1 [main] trec_eval 1576 find_fast_cwd: WARNING: Couldn't compute FAST_CWD pointer.  Please report this problem to\n",
    "the public mailing list cygwin@cygwin.com\n",
    "map_cut_15              all     0.0347\n",
    "\n",
    "C:\\Users\\user\\Downloads\\trec_eval>trec_eval -m map_cut.20 qrels.qrel results_hyper_hypo_20.txt\n",
    "      1 [main] trec_eval 12700 find_fast_cwd: WARNING: Couldn't compute FAST_CWD pointer.  Please report this problem to\n",
    "the public mailing list cygwin@cygwin.com\n",
    "map_cut_20              all     0.0361"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a15f775",
   "metadata": {},
   "source": [
    "In summary, our results:\n",
    "\n",
    "| Evaluation Metric       | Results   | Value  |\n",
    "|-------------------------|-----------|--------|\n",
    "| MAP (Mean Avg Precision) | All       | 0.0420 |\n",
    "| avgPre@5 (map_cut.5)     | k = 5    | 0.0266 |\n",
    "| avgPre@10 (map_cut.10)   | k = 10   | 0.0308 |\n",
    "| avgPre@15 (map_cut.15)   | k = 15   | 0.0333 |\n",
    "| avgPre@20 (map_cut.20)   | k = 20   | 0.0346 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5caae4",
   "metadata": {},
   "source": [
    "## 5. Analysis of Evaluation Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef66f7c",
   "metadata": {},
   "source": [
    "A table summarizing all our data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79b9002",
   "metadata": {},
   "source": [
    "| Evaluation Metric       | Results   | Original Answers | Expanded with Synonyms | Expanded with Hypernyms/Hyponyms |\n",
    "|-------------------------|-----------|-----------------|-----------------------|----------------------------------|\n",
    "| MAP (Mean Avg Precision) | All       | 0.0949          | 0.0454                | 0.0420                           |\n",
    "| avgPre@5 (map_cut.5)     | k = 5    | 0.0662          | 0.0304                | 0.0266                           |\n",
    "| avgPre@10 (map_cut.10)   | k = 10   | 0.0770          | 0.0352                | 0.0308                           |\n",
    "| avgPre@15 (map_cut.15)   | k = 15   | 0.0822          | 0.0371                | 0.0333                           |\n",
    "| avgPre@20 (map_cut.20)   | k = 20   | 0.0847          | 0.0384                | 0.0346                           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bd398f",
   "metadata": {},
   "source": [
    "* The original method showed the best performance across all evaluation metrics.  \n",
    "* Expanding the queries with synonyms significantly reduced performance, likely due to the addition of less relevant results.  \n",
    "* Expanding with hypernyms and hyponyms caused an even greater decrease in precision, indicating that this approach can introduce more noise into the search.  \n",
    "* Overall, query expansion does not guarantee improvement and requires a more selective approach.  \n",
    "* Query expansion can go wrong because it adds words that are not always relevant or specific to the original query, resulting in reduced precision due to noise and ambiguity in the search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11f040b",
   "metadata": {},
   "source": [
    "# Information Retrieval Systems - Phase 3  \n",
    "\n",
    "* In Phase 3, we will expand the queries of the `IR2025` collection with synonymous terms extracted from `word2vec`.  \n",
    "* Word2vec is an algorithm based on feedforward neural networks for learning vector representations of words that can be used to find words with similar meaning or words that appear in similar contexts.  \n",
    "* The model estimates the probability of selecting a word (output) based on its context (input).  \n",
    "* It extracts the nearest neighbors of a word by examining its contexts and determines when two words are semantically related (when they appear in the same or similar context).  \n",
    "* From this perspective, we can use the model to discover synonymous words.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350b8216",
   "metadata": {},
   "source": [
    "### 1. Training a word2vec Model  \n",
    "At this point, we will train a word2vec model using the `IR2025` collection as input and the `gensim` library, which provides implemented neural network models, such as word2vec, for Python.  \n",
    "\n",
    "For the model we will train, we need to decide the values of the following parameters:\n",
    "\n",
    "* `sentences` = The texts on which the model will be trained (a list of lists of words).  \n",
    "* `vector_size` = Number of dimensions of the embedding vector for each word (e.g., 100, 300).  \n",
    "* `window` = How many words before/after the current word will be considered as context.  \n",
    "* `min_count` = Words with frequency lower than this number are ignored (default: 5).  \n",
    "* `workers` = Number of threads to use for faster training (depending on CPU).  \n",
    "* `sg` = Choice of algorithm: 1 for Skip-gram, 0 for CBOW.  \n",
    "\n",
    "`Skip-gram`  \n",
    "* Predicts surrounding words based on the target word.  \n",
    "* More accurate with rare words.  \n",
    "* Requires more time and resources.  \n",
    "* Suitable for larger datasets and detailed representations.  \n",
    "\n",
    "`CBOW (Continuous Bag of Words)`  \n",
    "* Predicts the target word based on surrounding words (context).  \n",
    "* Faster to train.  \n",
    "* Works better with frequent words.  \n",
    "* Suitable for small datasets.  \n",
    "\n",
    "For starters, let's check the CPU configuration to select the number of workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "15572a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "print(multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7567903a",
   "metadata": {},
   "source": [
    "In our implementation:  \n",
    "\n",
    "* `sentences` = List of tokenized sentences from the IR2025 texts.  \n",
    "* `vector_size` = 50–100, to avoid overloading the model.  \n",
    "* `window` = 5, since our texts are long and context plays an important role.  \n",
    "* `min_count` = 1, because we will apply the model on a limited number of texts (1000), so we do not gain much by ignoring many words.  \n",
    "* `workers` = 4, based on the above `multiprocessing.cpu_count`.  \n",
    "* `sg` = 0, i.e., CBOW, which is better as it learns more stably and quickly on small datasets, like our 1000 queries.  \n",
    "\n",
    "Additionally, since we want to train the model on the texts of the `IR2025` collection, we will use the `updated_df` dataframe, specifically its `text` column. Since we already have the texts in a dataframe, we do not need to read them directly from the jsonl file for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "fb92a399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>authors</th>\n",
       "      <th>year</th>\n",
       "      <th>cited_by</th>\n",
       "      <th>references</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>632589828c8b9fca2c3a59e97451fde8fa7d188d</td>\n",
       "      <td>A hybrid of genetic algorithm and particle swa...</td>\n",
       "      <td>An evolutionary recurrent network which automa...</td>\n",
       "      <td>1</td>\n",
       "      <td>2004</td>\n",
       "      <td>432</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86e87db2dab958f1bd5877dc7d5b8105d6e31e46</td>\n",
       "      <td>A Hybrid EP and SQP for Dynamic Economic Dispa...</td>\n",
       "      <td>Dynamic economic dispatch (DED) is one of the ...</td>\n",
       "      <td>4</td>\n",
       "      <td>2002</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2a047d8c4c2a4825e0f0305294e7da14f8de6fd3</td>\n",
       "      <td>Genetic Fuzzy Systems - Evolutionary Tuning an...</td>\n",
       "      <td>It's not surprisingly when entering this site ...</td>\n",
       "      <td>4</td>\n",
       "      <td>2001</td>\n",
       "      <td>521</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        _id  \\\n",
       "0  632589828c8b9fca2c3a59e97451fde8fa7d188d   \n",
       "1  86e87db2dab958f1bd5877dc7d5b8105d6e31e46   \n",
       "2  2a047d8c4c2a4825e0f0305294e7da14f8de6fd3   \n",
       "\n",
       "                                               title  \\\n",
       "0  A hybrid of genetic algorithm and particle swa...   \n",
       "1  A Hybrid EP and SQP for Dynamic Economic Dispa...   \n",
       "2  Genetic Fuzzy Systems - Evolutionary Tuning an...   \n",
       "\n",
       "                                                text  authors  year  cited_by  \\\n",
       "0  An evolutionary recurrent network which automa...        1  2004       432   \n",
       "1  Dynamic economic dispatch (DED) is one of the ...        4  2002       169   \n",
       "2  It's not surprisingly when entering this site ...        4  2001       521   \n",
       "\n",
       "   references  \n",
       "0          10  \n",
       "1           0  \n",
       "2           0  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c9c0559b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\user\\anaconda3\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: gensim in c:\\users\\user\\anaconda3\\lib\\site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "47f29f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gensim \n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc01d270",
   "metadata": {},
   "source": [
    "* Below is the creation and invocation of a function that will be used to tokenize the sentences in the `text` column of `updated_df`, which will be used for training the `word2vec` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "6799f9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generator(dataframe, column_name):\n",
    "    sentences = []\n",
    "    for line in dataframe[column_name]:\n",
    "        try:\n",
    "            tokens = simple_preprocess(line, deacc=True)\n",
    "            if tokens:\n",
    "                sentences.append(tokens)\n",
    "        except json.JSONDecodeError:\n",
    "            continue\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ad1b9a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sentence_generator(updated_df, 'text')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa06f8a4",
   "metadata": {},
   "source": [
    "* Now we will train the model using the list of tokenized queries we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ef18fc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_word2vec(sentences):\n",
    "    model = Word2Vec(\n",
    "        sentences= sentences,          # list of tokenized queries\n",
    "        vector_size= 100,              # size of embedding\n",
    "        window= 5,                     # size of context window\n",
    "        min_count= 1,                  # ignores words with frequency < 1\n",
    "        workers= 4,                    # number of threads / workers\n",
    "        sg=0                           # 0 for CBOW (we would have 1 for skip-gram)\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "86c64162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as 'my_word2vec.model'.\n"
     ]
    }
   ],
   "source": [
    "model = train_word2vec(sentences)\n",
    "model.save(\"my_word2vec.model\")\n",
    "print(\"Model saved as 'my_word2vec.model'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "af373d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example: words  similar with 'learning':\n",
      "Top 5 words similar with 'learning':\n",
      "learningmodels: 0.6712\n",
      "translation: 0.6494\n",
      "adaptation: 0.6166\n",
      "learnings: 0.6110\n",
      "training: 0.5544\n",
      "\n",
      "Example: words  similar with 'economic':\n",
      "Top 5 words  similar with 'economic':\n",
      "sustainability: 0.8057\n",
      "capital: 0.7998\n",
      "socio: 0.7995\n",
      "financial: 0.7805\n",
      "corporate: 0.7730\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nExample: words  similar with 'learning':\")\n",
    "word = \"learning\"\n",
    "if word in model.wv:\n",
    "    similar_words = model.wv.most_similar(word, topn=5)\n",
    "    print(f\"Top 5 words similar with '{word}':\")\n",
    "    for w, score in similar_words:\n",
    "        print(f\"{w}: {score:.4f}\")\n",
    "else:\n",
    "    print(f\"Word '{word}' not found in the model's dictionary.\")\n",
    "\n",
    "print(\"\\nExample: words  similar with 'economic':\")\n",
    "word = \"economic\"\n",
    "if word in model.wv:\n",
    "    similar_words = model.wv.most_similar(word, topn=5)\n",
    "    print(f\"Top 5 words  similar with '{word}':\")\n",
    "    for w, score in similar_words:\n",
    "        print(f\"{w}: {score:.4f}\")\n",
    "else:\n",
    "    print(f\"Word '{word}' not found in the model's dictionary.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfd54d9",
   "metadata": {},
   "source": [
    "* Our model appears to be ready."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5e088c",
   "metadata": {},
   "source": [
    "### 2. Expanding IR2025 Queries with Synonymous Terms from the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd9a26c",
   "metadata": {},
   "source": [
    "* Below is a function that will be used to create a corresponding list of tokens for each query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "944723a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '78495383450e02c5fe817e408726134b3084905d',\n",
       " 'text': 'A Direct Search Method to solve Economic Dispatch Problem with Valve-Point Effect',\n",
       " 'metadata': {'authors': ['50306438', '15303316', '1976596'],\n",
       "  'year': 2014,\n",
       "  'cited_by': ['38e78343cfd5c013decf49e8cf008ddf6458200f'],\n",
       "  'references': ['632589828c8b9fca2c3a59e97451fde8fa7d188d',\n",
       "   '4cf296b9d4ef79b838dc565e6e84ab9b089613de',\n",
       "   '86e87db2dab958f1bd5877dc7d5b8105d6e31e46',\n",
       "   '4b031fa8bf63e17e2100cf31ba6e11d8f80ff2a8',\n",
       "   'a718c6ca7a1db49bb2328d43f775783e8ec6f985',\n",
       "   'cf51cfb5b221500b882efee60b794bc11635267e',\n",
       "   '6329874126a4e753f98c40eaa74b666d0f14eaba',\n",
       "   'a27b6025d147febb54761345eafdd73954467aca']}}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "2ecfe1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_tokenization(query_list):\n",
    "    queries_tokenized = []\n",
    "    for query in query_list:\n",
    "        try:\n",
    "            tokens = simple_preprocess(query['text'], deacc=True)\n",
    "            if tokens:\n",
    "                queries_tokenized.append(tokens)\n",
    "        except json.JSONDecodeError:\n",
    "            continue\n",
    "    return queries_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "9707746b",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_tokenized = query_tokenization(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "8ad2c655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(queries_tokenized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4532ffcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['direct',\n",
       " 'search',\n",
       " 'method',\n",
       " 'to',\n",
       " 'solve',\n",
       " 'economic',\n",
       " 'dispatch',\n",
       " 'problem',\n",
       " 'with',\n",
       " 'valve',\n",
       " 'point',\n",
       " 'effect']"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_tokenized[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a3472a",
   "metadata": {},
   "source": [
    "* We will expand the queries by adding, for each word, 4 synonyms suggested by our model.  \n",
    "* We will limit to 4 synonyms to maintain consistency with the previous phase of the assignment, where we also kept 4 synonyms.  \n",
    "* We will not handle stopwords at this point because our index already has a built-in analyzer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "444c0296",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_extended = []\n",
    "for query in queries_tokenized:\n",
    "    new_query = list(query)\n",
    "    for token in query: \n",
    "        if token in model.wv:\n",
    "            similar_words = model.wv.most_similar(token, topn=4)\n",
    "            for similar_word in similar_words:\n",
    "                new_query.append(similar_word[0])\n",
    "    new_query = list( dict.fromkeys(new_query) ) # to remove duplicates\n",
    "    query_str = ' '.join(new_query)\n",
    "    queries_extended.append(query_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "aaa2f369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(queries_extended))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "0ee4af14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1 before adding synonyms:\n",
      "A Direct Search Method to solve Economic Dispatch Problem with Valve-Point Effect\n",
      "\n",
      "Query 1 after adding synonyms:\n",
      "direct search method to solve economic dispatch problem with valve point effect indirect feedback hookup haptic searching query searches recommendation technique approach algorithm scheme able quickly ability effectively tackle resolve address overcome sustainability capital socio financial auction eventual syllogism intertemporal problems issue challenge task sanctuary parasubiculum commonplaces roadsides electrostatic solenoid hbt mcu points clouds starting view effects impact dependence influence\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Query 1 before adding synonyms:\\n{queries[0]['text']}\\n\")\n",
    "print(f\"Query 1 after adding synonyms:\\n{queries_extended[0]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b3ef80",
   "metadata": {},
   "source": [
    "* It appears that we have successfully expanded our queries with synonyms generated by the model we trained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec34343",
   "metadata": {},
   "source": [
    "## 3. Executing Queries  \n",
    "In this step, we will run the queries, now expanded with synonyms, on the index and collect the machine's responses. We will use the queries that were already available in the `scidocs` folder, which we also used for building the indexes. We will keep the top k retrieved documents, for `k = 20, 30, 50`.  \n",
    "* We will use the `search_document` function from Phase 1, which performs a single query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "96bb86d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(queries))\n",
    "print(len(queries_extended))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "7221a950",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for i in range (0,1000):\n",
    "    query_text = queries_extended[i]\n",
    "    query_id = queries[i]['_id']\n",
    "    if not query_text:\n",
    "        continue\n",
    "    \n",
    "    response = search_document(query_text, size=1000)  \n",
    "    hits = response['hits']['hits']\n",
    "    \n",
    "    if not hits:\n",
    "        print(\"  No results found.\\n\")\n",
    "        continue\n",
    "    \n",
    "    results_list = []\n",
    "    for hit in hits:\n",
    "        id = hit['_id']\n",
    "        source = hit['_source']\n",
    "        score = hit['_score']\n",
    "        title = source.get('title', 'N/A')\n",
    "        text = source.get('text', 'N/A')\n",
    "        results_list.append((id, title, text, score))\n",
    "    \n",
    "    data.append({\n",
    "        \"query_id\": query_id,\n",
    "        \"query\": query_text,\n",
    "        \"results\": results_list\n",
    "    })\n",
    "dfs_all_word2vec = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "4cb560f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = [5, 10, 15, 20, 30, 50]\n",
    "dfs_synonyms = {}\n",
    "\n",
    "for k in k_values:\n",
    "    data = []\n",
    "    \n",
    "    for i in range (0,1000):\n",
    "        query_text = queries_extended[i]\n",
    "        query_id = queries[i]['_id']\n",
    "        if not query_text:\n",
    "            continue\n",
    "        \n",
    "        response = search_document(query_text, size=k)\n",
    "        hits = response['hits']['hits']\n",
    "        \n",
    "        if not hits:\n",
    "            print(f\"No results found for query ID {query_id}.\\n\")\n",
    "            continue\n",
    "        \n",
    "        results_list = []\n",
    "        for hit in hits:\n",
    "            id = hit['_id']\n",
    "            source = hit['_source']\n",
    "            score = hit['_score']\n",
    "            title = source.get('title', 'N/A')\n",
    "            text = source.get('text', 'N/A')\n",
    "            results_list.append((id, title, text, score))\n",
    "        \n",
    "        data.append({\n",
    "            \"query_id\": query_id,\n",
    "            \"query\": query_text,\n",
    "            \"results\": results_list\n",
    "        })\n",
    "    \n",
    "    dfs_synonyms[k] = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f025bd20",
   "metadata": {},
   "source": [
    "* We see that there were **responses to all our queries**.  \n",
    "* `dfs_synonyms` is a dictionary where each key is one of the k values (5, 10, 15, 20, 30, 50) and each value is a pandas DataFrame (as in Phase 1 and 2, Part 3).  \n",
    "* Let's examine the content of this dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "c7f41b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_synonyms[20].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "8aa28909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_synonyms[30].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "b740d4eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_synonyms[50].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "ed404ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1000.0\n",
       "mean       20.0\n",
       "std         0.0\n",
       "min        20.0\n",
       "25%        20.0\n",
       "50%        20.0\n",
       "75%        20.0\n",
       "max        20.0\n",
       "Name: results, dtype: float64"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_synonyms[20]['results'].apply(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "74b08a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1000.0\n",
       "mean       30.0\n",
       "std         0.0\n",
       "min        30.0\n",
       "25%        30.0\n",
       "50%        30.0\n",
       "75%        30.0\n",
       "max        30.0\n",
       "Name: results, dtype: float64"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_synonyms[30]['results'].apply(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "9fda0e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1000.0\n",
       "mean       50.0\n",
       "std         0.0\n",
       "min        50.0\n",
       "25%        50.0\n",
       "50%        50.0\n",
       "75%        50.0\n",
       "max        50.0\n",
       "Name: results, dtype: float64"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_synonyms[50]['results'].apply(len).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6650295",
   "metadata": {},
   "source": [
    "In general, for each k = 20, 30, 50 we observe:  \n",
    "\n",
    "* **count**: 1000 → There are 1000 queries in the DataFrame, so 1000 searches were performed.  \n",
    "\n",
    "* **mean**: k → Each query returned exactly k results on average.  \n",
    "\n",
    "* **std**: 0 → The standard deviation is 0, meaning all queries returned exactly k results each time with no deviation.  \n",
    "\n",
    "* **min**, **25%**, **50%**, **75%**, **max**: k → The min, max, and percentile values are all k, so there is no query with fewer or more results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b93fd3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Statistic     Value\n",
      "0                Mean  5.709842\n",
      "1              Median  5.501593\n",
      "2  Standard Deviation  1.693263\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "all_scores = [result[3] for row in dfs_synonyms[20]['results'] for result in row]\n",
    "\n",
    "mean_score = np.mean(all_scores)\n",
    "median_score = np.median(all_scores)\n",
    "std_score = np.std(all_scores)\n",
    "\n",
    "stats_df = pd.DataFrame({\n",
    "    \"Statistic\": [\"Mean\", \"Median\", \"Standard Deviation\"],\n",
    "    \"Value\": [mean_score, median_score, std_score]\n",
    "})\n",
    "\n",
    "print(stats_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3730f61b",
   "metadata": {},
   "source": [
    "* **Average score:** approximately 5.68  \n",
    "* **Median score:** approximately 5.46  \n",
    "* **Std of score:** approximately 1.7 (indicating some variability in the scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "90da14bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Statistic     Value\n",
      "0                Mean  5.457026\n",
      "1              Median  5.256280\n",
      "2  Standard Deviation  1.639950\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "all_scores = [result[3] for row in dfs_synonyms[30]['results'] for result in row]\n",
    "\n",
    "mean_score = np.mean(all_scores)\n",
    "median_score = np.median(all_scores)\n",
    "std_score = np.std(all_scores)\n",
    "\n",
    "stats_df = pd.DataFrame({\n",
    "    \"Statistic\": [\"Mean\", \"Median\", \"Standard Deviation\"],\n",
    "    \"Value\": [mean_score, median_score, std_score]\n",
    "})\n",
    "\n",
    "print(stats_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43db5ef",
   "metadata": {},
   "source": [
    "* **Average score:** approximately 5.42  \n",
    "* **Median score:** approximately 5.21  \n",
    "* **Std of score:** approximately 1.65 (again, indicating variability in the scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "dab83e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Statistic     Value\n",
      "0                Mean  5.128986\n",
      "1              Median  4.935660\n",
      "2  Standard Deviation  1.573381\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "all_scores = [result[3] for row in dfs_synonyms[50]['results'] for result in row]\n",
    "\n",
    "mean_score = np.mean(all_scores)\n",
    "median_score = np.median(all_scores)\n",
    "std_score = np.std(all_scores)\n",
    "\n",
    "stats_df = pd.DataFrame({\n",
    "    \"Statistic\": [\"Mean\", \"Median\", \"Standard Deviation\"],\n",
    "    \"Value\": [mean_score, median_score, std_score]\n",
    "})\n",
    "\n",
    "print(stats_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3307af27",
   "metadata": {},
   "source": [
    "* **Average score:** approximately 5.09  \n",
    "* **Median score:** approximately 4.89  \n",
    "* **Std of score:** approximately 1.58 (indicating variability in the scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10fee97",
   "metadata": {},
   "source": [
    "Let's examine the relevance score performance across all k and for all query categories:\n",
    "\n",
    "| Case                        | k  | Mean      | Median    | Std         |\n",
    "|------------------------------|----|-----------|-----------|-------------|\n",
    "| Simple                       | 20 | 2.795202  | 2.599902  | 0.939617    |\n",
    "| Simple                       | 30 | 2.625898  | 2.439002  | 0.891223    |\n",
    "| Simple                       | 50 | 2.412677  | 2.237310  | 0.831417    |\n",
    "| Synonyms WordNet             | 20 | 4.110391  | 3.937426  | 1.535066    |\n",
    "| Synonyms WordNet             | 30 | 3.898443  | 3.727660  | 1.462083    |\n",
    "| Synonyms WordNet             | 50 | 3.626761  | 3.474216  | 1.372217    |\n",
    "| Hypernyms & Hyponyms WordNet | 20 | 6.367802 | 6.029314 | 2.323537   |\n",
    "| Hypernyms & Hyponyms WordNet | 30 | 6.077830 | 5.750344 | 2.239387   |\n",
    "| Hypernyms & Hyponyms WordNet | 50 | 5.704961 | 5.394706 | 2.132761   |\n",
    "| Synonyms word2vec            | 20 | 5.681937  | 5.463569  | 1.708562    |\n",
    "| Synonyms word2vec            | 30 | 5.426382  | 5.216836  | 1.651440    |\n",
    "| Synonyms word2vec            | 50 | 5.096679  | 4.898412  | 1.580485    |\n",
    "\n",
    "The **Hypernyms & Hyponyms WordNet** approach has:  \n",
    "* The highest mean for all k.  \n",
    "* Consistently better median.  \n",
    "* Although it has higher variability (Std), its overall result is clearly superior.  \n",
    "\n",
    "However, comparing the **synonym approaches**, the word2vec-based synonyms we implemented in this phase have **consistently higher scores** than the WordNet synonyms from Phase 2 for all k. Additionally, it has slightly lower standard deviation, indicating **more stable performance**.  \n",
    "\n",
    "**Thus, the ranking is:**  \n",
    "1. **Hypernyms & Hyponyms WordNet**  \n",
    "2. **Synonyms word2vec**  \n",
    "3. **Synonyms WordNet**  \n",
    "4. **Simple method**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2388b08",
   "metadata": {},
   "source": [
    "# 4. Evaluation of Results  \n",
    "At this point, we will once again evaluate our responses by comparing them to the correct answers using the `trec_eval` evaluation tool.  \n",
    "\n",
    "We will check the evaluation metrics:  \n",
    "* **MAP (mean average precision)**  \n",
    "* **avgPre@k (average precision at the top k retrieved documents)** for k = 5, 10, 15, 20, and for both query expansion approaches.  \n",
    "\n",
    "We will modify our data so that it is stored in a format suitable for `trec_eval`, as in Phase 1 of the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "af3c56eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created:\n",
      "- C://Users//user//Downloads//trec_eval\\results_word2vec.txt\n",
      "- results_word2vec.txt\n"
     ]
    }
   ],
   "source": [
    "trec_dir = r\"C://Users//user//Downloads//trec_eval\"\n",
    "filename = \"results_word2vec.txt\"\n",
    "full_path_trec = f\"{trec_dir}\\\\{filename}\"\n",
    "full_path_local = filename\n",
    "\n",
    "with open(full_path_trec, \"w\") as f_trec, open(full_path_local, \"w\") as f_local:\n",
    "    for _, row in dfs_all_word2vec.iterrows():\n",
    "        query_id = row[\"query_id\"]\n",
    "        results = row[\"results\"]\n",
    "\n",
    "        for rank, (docno, title, text, score) in enumerate(results, start=1):\n",
    "            line = f\"{query_id} 0 {docno} {rank} {score:.4f} results_word2vec\\n\"\n",
    "            f_trec.write(line)\n",
    "            f_local.write(line)\n",
    "\n",
    "print(f\"Created:\\n- {full_path_trec}\\n- {full_path_local}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "421d1269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created:\n",
      "- C://Users//user//Downloads//trec_eval\\results_word2vec_5.txt\n",
      "- results_word2vec_5.txt\n",
      "Created:\n",
      "- C://Users//user//Downloads//trec_eval\\results_word2vec_10.txt\n",
      "- results_word2vec_10.txt\n",
      "Created:\n",
      "- C://Users//user//Downloads//trec_eval\\results_word2vec_15.txt\n",
      "- results_word2vec_15.txt\n",
      "Created:\n",
      "- C://Users//user//Downloads//trec_eval\\results_word2vec_20.txt\n",
      "- results_word2vec_20.txt\n"
     ]
    }
   ],
   "source": [
    "trec_dir = r\"C://Users//user//Downloads//trec_eval\"\n",
    "\n",
    "for k in dfs_synonyms:\n",
    "    if(k<30):\n",
    "        df = dfs_synonyms[k]\n",
    "        filename = f\"results_word2vec_{k}.txt\"\n",
    "        full_path_trec = f\"{trec_dir}\\\\{filename}\"\n",
    "        full_path_local = filename\n",
    "\n",
    "        with open(full_path_trec, \"w\") as f_trec, open(full_path_local, \"w\") as f_local:\n",
    "            for _, row in df.iterrows():\n",
    "                query_id = row[\"query_id\"]\n",
    "                results = row[\"results\"]\n",
    "\n",
    "                for rank, (docno, title, text, score) in enumerate(results, start=1):\n",
    "                    line = f\"{query_id} 0 {docno} {rank} {score:.4f} results_{k}\\n\"\n",
    "                    f_trec.write(line)\n",
    "                    f_local.write(line)\n",
    "\n",
    "        print(f\"Created:\\n- {full_path_trec}\\n- {full_path_local}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8a61e8",
   "metadata": {},
   "source": [
    "* Now that we have created the txt files, we will execute the corresponding commands in the cmd.  \n",
    "* We will first examine the case of queries expanded with synonyms.  \n",
    "* Below is a snippet of the commands I ran in the cmd as a copy-paste:\n",
    "\n",
    "\n",
    "```bash\n",
    "C:\\Users\\user>cd C:\\Users\\user\\Downloads\\trec_eval\n",
    "\n",
    "C:\\Users\\user\\Downloads\\trec_eval>trec_eval -m map qrels.qrel results_word2vec.txt\n",
    "      1 [main] trec_eval 10248 find_fast_cwd: WARNING: Couldn't compute FAST_CWD pointer.  Please report this problem to\n",
    "the public mailing list cygwin@cygwin.com\n",
    "map                     all     0.0525\n",
    "\n",
    "C:\\Users\\user\\Downloads\\trec_eval>trec_eval -m map_cut.5 qrels.qrel results_word2vec_5.txt\n",
    "      1 [main] trec_eval 2776 find_fast_cwd: WARNING: Couldn't compute FAST_CWD pointer.  Please report this problem to\n",
    "the public mailing list cygwin@cygwin.com\n",
    "map_cut_5               all     0.0324\n",
    "\n",
    "C:\\Users\\user\\Downloads\\trec_eval>trec_eval -m map_cut.10 qrels.qrel results_word2vec_10.txt\n",
    "      1 [main] trec_eval 7880 find_fast_cwd: WARNING: Couldn't compute FAST_CWD pointer.  Please report this problem to\n",
    "the public mailing list cygwin@cygwin.com\n",
    "map_cut_10              all     0.0393\n",
    "\n",
    "C:\\Users\\user\\Downloads\\trec_eval>trec_eval -m map_cut.15 qrels.qrel results_word2vec_15.txt\n",
    "      1 [main] trec_eval 12520 find_fast_cwd: WARNING: Couldn't compute FAST_CWD pointer.  Please report this problem to\n",
    "the public mailing list cygwin@cygwin.com\n",
    "map_cut_15              all     0.0424\n",
    "\n",
    "C:\\Users\\user\\Downloads\\trec_eval>trec_eval -m map_cut.20 qrels.qrel results_word2vec_20.txt\n",
    "      1 [main] trec_eval 7452 find_fast_cwd: WARNING: Couldn't compute FAST_CWD pointer.  Please report this problem to\n",
    "the public mailing list cygwin@cygwin.com\n",
    "map_cut_20              all     0.0442"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4b2917",
   "metadata": {},
   "source": [
    "In summary, our results:\n",
    "\n",
    "| Evaluation Metric         | Results            | Value  |\n",
    "|---------------------------|------------------|--------|\n",
    "| MAP (Mean Avg Precision)  | All                | 0.0519 |\n",
    "| avgPre@5 (map_cut.5)      | k = 5             | 0.0325 |\n",
    "| avgPre@10 (map_cut.10)    | k = 10            | 0.0384 |\n",
    "| avgPre@15 (map_cut.15)    | k = 15            | 0.0416 |\n",
    "| avgPre@20 (map_cut.20)    | k = 20            | 0.0431 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d686de16",
   "metadata": {},
   "source": [
    "## 5. Analysis of Evaluation Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a2c9a6",
   "metadata": {},
   "source": [
    "A summary table of all our results:\n",
    "\n",
    "| Evaluation Metric         | Results | Original Responses | Expanded with WordNet Synonyms | Expanded with WordNet Hypernyms/Hyponyms | Expanded with word2vec Synonyms |\n",
    "|---------------------------|---------|------------------|-------------------------------|-----------------------------------------|--------------------------------|\n",
    "| MAP (Mean Avg Precision)  | All     | 0.0949           | 0.0454                        | 0.0420                                  | 0.0519                         |\n",
    "| avgPre@5 (map_cut.5)      | k = 5   | 0.0662           | 0.0304                        | 0.0266                                  | 0.0325                         |\n",
    "| avgPre@10 (map_cut.10)    | k = 10  | 0.0770           | 0.0352                        | 0.0308                                  | 0.0384                         |\n",
    "| avgPre@15 (map_cut.15)    | k = 15  | 0.0822           | 0.0371                        | 0.0333                                  | 0.0416                         |\n",
    "| avgPre@20 (map_cut.20)    | k = 20  | 0.0847           | 0.0384                        | 0.0346                                  | 0.0431                         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edac351",
   "metadata": {},
   "source": [
    "* The original approach, i.e., without query expansion, achieved the best performance across all evaluation metrics.  \n",
    "* Expanding queries with hypernyms, hyponyms, or synonyms (by any method) appears ineffective.  \n",
    "* Query expansion can fail because it adds words that are not always relevant or specific to the original query, resulting in reduced precision due to noise and ambiguity in the search.  \n",
    "\n",
    "**However, queries expanded with word2vec synonyms were more effective than any other expansion method besides the original queries.**  \n",
    "**Thus, the final ranking of the methods is:**  \n",
    "1. **Simple method, without query expansion**  \n",
    "2. **Queries expanded with word2vec synonyms**  \n",
    "3. **Queries expanded with WordNet synonyms or hypernyms/hyponyms**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
